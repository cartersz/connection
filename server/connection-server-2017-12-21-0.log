[2017-12-21 00:16:13.367] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:13.377] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:13.377] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:16.380] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:16.428] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:16.429] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:16.539] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:19.546] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 00:16:20.435] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 00:16:20.436] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 00:16:20.442] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 10
[2017-12-21 00:16:20.443] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 00:16:20.489] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 00:16:28.437] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:28.437] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:28.838] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:28.838] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:43.906] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:43.908] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:43.916] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:43.916] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:46.923] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.923] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.923] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.923] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.924] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.924] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.924] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.924] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.924] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.925] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.925] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.925] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.925] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.926] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.926] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.926] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.926] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:46.927] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 00:16:47.077] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:47.077] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 00:16:50.081] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 00:16:50.081] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 00:16:50.616] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 00:16:50.616] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 00:16:50.616] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 00:16:50.616] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 00:16:50.750] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 00:16:51.666] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 00:16:51.667] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 00:16:51.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 11
[2017-12-21 00:16:51.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 11
[2017-12-21 00:16:51.672] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 00:16:51.672] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 00:16:51.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 11
[2017-12-21 00:16:51.673] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 00:16:51.674] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 00:16:51.675] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 00:16:51.677] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 01:10:05.349] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 01:10:05.349] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 01:10:05.349] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:24.662] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:24.663] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:24.664] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:27.675] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:27.705] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:27.706] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:27.814] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:30.827] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 02:58:31.488] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 02:58:31.489] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 02:58:31.494] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 13
[2017-12-21 02:58:31.495] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 02:58:31.499] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 02:58:39.703] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:39.703] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:39.799] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:39.799] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.812] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.813] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.813] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.813] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.813] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.813] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.814] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.814] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.814] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.814] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.815] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 02:58:51.867] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:51.868] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 02:58:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 02:58:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 02:58:55.624] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 02:58:55.624] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 02:58:55.625] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 02:58:55.625] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 02:58:58.622] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 02:58:58.652] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 02:58:58.652] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 02:58:58.727] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 14
[2017-12-21 02:58:58.727] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 14
[2017-12-21 02:58:58.727] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 02:58:58.727] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 02:58:58.730] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 02:58:58.730] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 02:58:58.826] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 14
[2017-12-21 02:58:58.827] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 02:58:59.031] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 03:52:11.344] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 03:52:11.344] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 03:52:11.344] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:27.453] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:27.453] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:27.455] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:30.466] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:30.499] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:30.500] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:30.613] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:33.618] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 04:46:34.428] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 04:46:34.428] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 04:46:34.433] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 16
[2017-12-21 04:46:34.434] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 04:46:34.438] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 04:46:42.482] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:42.482] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:42.848] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:42.850] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:54.876] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.876] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.876] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.876] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.876] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.877] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.878] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.878] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.878] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.878] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.879] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.879] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.915] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:54.915] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:54.917] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:54.917] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 04:46:55.026] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:55.026] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 04:46:58.037] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 04:46:58.037] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 04:46:58.575] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 04:46:58.575] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 04:46:58.575] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 04:46:58.575] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 04:47:01.566] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 04:47:01.597] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 04:47:01.598] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 04:47:01.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 17
[2017-12-21 04:47:01.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 17
[2017-12-21 04:47:01.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 04:47:01.671] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 04:47:01.674] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 04:47:01.674] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 04:47:01.771] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 17
[2017-12-21 04:47:01.772] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 04:47:01.976] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 05:40:15.339] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 05:40:15.339] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 05:40:15.339] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:05.621] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:05.648] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:05.651] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:08.663] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:08.672] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:08.673] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:08.786] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:11.798] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 06:20:12.481] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 06:20:12.482] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 06:20:12.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 19
[2017-12-21 06:20:12.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 06:20:12.503] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 06:20:20.652] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:20.692] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:20.970] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:20.970] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:36.014] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:36.014] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:36.285] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:36.285] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:39.298] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.299] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.300] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.300] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.300] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.300] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.300] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.301] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.301] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.301] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.301] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.302] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.302] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 06:20:39.643] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 06:20:39.643] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 07:13:51.331] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 07:13:51.337] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 07:13:51.338] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:43:34.617] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:34.626] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:34.652] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:37.663] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:43:37.696] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:37.697] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:43:37.810] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:40.816] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 08:43:41.471] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 08:43:41.472] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 08:43:41.477] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 21
[2017-12-21 08:43:41.477] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 08:43:41.482] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 08:43:49.655] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:43:49.668] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:43:49.863] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:43:49.863] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:44:01.888] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.888] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.888] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.888] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.889] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.890] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.890] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.890] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.890] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.891] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.891] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 08:44:01.940] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:44:01.941] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 08:44:04.950] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 08:44:04.950] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 08:44:05.610] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 08:44:05.610] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 08:44:05.610] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 08:44:05.610] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 08:44:08.628] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 08:44:09.628] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 08:44:09.629] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 08:44:09.654] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 22
[2017-12-21 08:44:09.654] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 22
[2017-12-21 08:44:09.654] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 08:44:09.655] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 08:44:09.657] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 08:44:09.657] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 08:44:09.754] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 22
[2017-12-21 08:44:09.755] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 08:44:09.959] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 09:16:09.328] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:16:09.329] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:16:09.330] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:17:40.663] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:17:40.834] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:17:40.836] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:17:55.680] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:17:55.843] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:17:55.850] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:18:13.793] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:18:28.813] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:18:29.044] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:18:44.065] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:18:44.093] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:18:59.111] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:18:59.349] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:19:14.363] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:14.402] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:19:15.443] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:19:15.994] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:19:18.451] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 09:19:18.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 09:19:18.503] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:18.506] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 24
[2017-12-21 09:19:18.507] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 09:19:18.509] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 09:19:18.997] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 09:19:19.027] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.027] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.027] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.027] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.027] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.028] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.028] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.028] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.028] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.029] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.029] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.029] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.030] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.030] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.030] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.030] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.031] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.031] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.031] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.032] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:19:19.420] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:19:19.507] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 09:19:19.508] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:21.510] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-2, connection-test-1] for group 0
[2017-12-21 09:19:21.520] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 09:19:21.520] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:21.543] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 25
[2017-12-21 09:19:21.543] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 25
[2017-12-21 09:19:21.544] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0, connection-test-1] for group 0
[2017-12-21 09:19:21.544] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 09:19:21.750] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 09:19:21.750] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-1]
[2017-12-21 09:19:22.426] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 09:19:22.516] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 09:19:22.516] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:24.548] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 09:19:24.548] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0, connection-test-1] for group 0
[2017-12-21 09:19:24.760] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-1]
[2017-12-21 09:19:24.761] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 09:19:24.761] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:24.761] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:19:24.764] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 26
[2017-12-21 09:19:24.764] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 26
[2017-12-21 09:19:24.764] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 26
[2017-12-21 09:19:24.765] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 09:19:24.765] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 09:19:24.765] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 09:19:24.767] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 09:19:24.768] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 09:19:24.768] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 09:22:00.948] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:22:01.016] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:22:01.066] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:22:40.110] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:22:40.110] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:22:40.111] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 09:22:40.111] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 09:22:40.302] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:22:40.302] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 09:22:40.386] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 09:22:40.387] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 09:22:40.387] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 09:22:40.387] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:22:40.387] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:22:40.387] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:22:40.390] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:22:40.416] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 29
[2017-12-21 09:22:40.416] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 29
[2017-12-21 09:22:40.416] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 09:22:40.416] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 29
[2017-12-21 09:22:40.417] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 09:22:40.417] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 09:22:40.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 09:22:40.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 09:22:40.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 09:23:28.519] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:23:28.519] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:23:28.564] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:24:22.384] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:24:22.384] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:24:22.440] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:24:25.397] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 09:24:25.398] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 09:24:25.506] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 09:24:26.001] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 09:24:26.001] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 09:24:26.001] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 09:24:26.001] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:24:26.002] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:24:26.002] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:24:26.007] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 32
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 32
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 32
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 09:24:26.013] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 09:24:26.018] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 09:24:26.018] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 09:24:26.019] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 09:29:09.305] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:29:09.306] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:29:09.306] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:33:14.402] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:33:14.402] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:33:14.402] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 09:33:17.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 09:33:17.408] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 09:33:17.408] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 09:33:17.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 09:33:17.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 09:33:17.488] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:33:17.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 09:33:17.488] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:33:17.488] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:33:17.492] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 35
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 35
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 35
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 09:33:17.497] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 09:33:17.501] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 09:33:17.501] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 09:33:17.501] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 09:42:09.751] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 09:42:10.218] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:27.251] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:27.252] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:27.252] [INFO ] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:28.373] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:28.377] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:28.377] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:31.455] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:31.455] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:31.461] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 618] - Marking the coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) dead for group 0
[2017-12-21 10:20:31.585] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:31.585] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:31.585] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:20:34.624] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-1] for group 0
[2017-12-21 10:20:34.624] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-0] for group 0
[2017-12-21 10:20:34.624] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [connection-test-2] for group 0
[2017-12-21 10:20:35.296] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 10:20:35.296] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 10:20:35.296] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 10:20:35.297] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:20:35.297] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:20:35.297] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:20:35.302] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:20:35.308] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 38
[2017-12-21 10:20:35.308] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 38
[2017-12-21 10:20:35.308] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:20:35.308] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:20:35.309] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 38
[2017-12-21 10:20:35.309] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:20:35.314] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:20:35.314] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:20:35.314] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:42:20.005] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:42:20.007] [INFO ] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 689] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[2017-12-21 10:42:20.728] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:42:20.728] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:42:20.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:42:26.374] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 10:42:26.452] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 10:42:26 CST 2017]; root of context hierarchy
[2017-12-21 10:42:26.497] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 10:42:26.591] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 10:42:26.617] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 10:42:26.893] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 46] - Starting TCP Server...
[2017-12-21 10:42:26.991] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 61] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 10:42:27.047] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.096] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.138] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:42:27.139] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:42:27.144] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.144] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.147] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:42:27.147] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:42:27.149] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.150] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:42:27.154] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:42:27.154] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:42:27.160] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:42:27.163] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:42:27.164] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 10:42:27.210] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:42:27.213] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:42:27.213] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:42:27.213] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:42:27.213] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:42:27.213] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:42:27.214] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:42:27.214] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:42:27.215] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:42:27.215] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:42:27.215] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:42:27.215] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:42:27.222] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:42:27.225] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 41
[2017-12-21 10:42:27.225] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 41
[2017-12-21 10:42:27.225] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 41
[2017-12-21 10:42:27.226] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:42:27.226] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:42:27.226] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:42:27.233] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:42:27.233] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:42:27.233] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:42:41.589] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 10:42:41.595] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 10:42:41.596] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 10:42:41.596] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 10:42:41.694] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 10:42:41.699] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 10:42:41.717] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:42:41.967] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:42:41.975] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:42:41.976] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:42:41.977] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:42:41.998] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:42:42.001] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:42:42.017] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:42:42.205] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:42:42.205] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 10:42:42.280] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:42:42.284] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 180] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[2017-12-21 10:42:42.294] [WARN ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 188] - The configuration 'group.id' was supplied but isn't a known config.
[2017-12-21 10:42:42.295] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:42:42.295] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:42:42.320] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 10:42:42.320] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 10:42:42.320] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 10:42:42.321] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 10:42:42.321] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 10:42:42.321] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:42:42.321] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-1@20
[2017-12-21 10:42:42.321] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 10:42:42.321] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:42:42.322] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:42:42.336] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:42:42.337] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:42:42.343] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:42:42.344] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:42:42.344] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:42:42.348] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:42:42.350] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:42:42.356] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:42:42.357] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:44:42.090] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 10:44:42.091] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 10:49:55.422] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:49:55.425] [INFO ] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 689] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[2017-12-21 10:49:55.507] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:49:55.507] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:49:55.628] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:50:01.523] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 10:50:01.601] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 10:50:01 CST 2017]; root of context hierarchy
[2017-12-21 10:50:01.646] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 10:50:01.737] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 10:50:01.764] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 10:50:02.049] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 51] - Starting TCP Server...
[2017-12-21 10:50:02.167] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 67] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 10:50:02.229] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.288] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.330] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:50:02.330] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:50:02.335] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.336] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.339] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:50:02.339] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:50:02.340] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.341] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:50:02.344] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:50:02.345] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:50:02.351] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:50:02.353] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:50:02.354] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 10:50:02.404] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:50:02.405] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:50:02.405] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:50:02.407] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:50:02.408] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:50:02.408] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:50:02.416] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:50:02.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 44
[2017-12-21 10:50:02.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 44
[2017-12-21 10:50:02.419] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 44
[2017-12-21 10:50:02.420] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:50:02.420] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:50:02.420] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:50:02.427] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:50:02.427] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:50:02.427] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:51:59.343] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:51:59.773] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:51:59.774] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:51:59.774] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:52:04.660] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 10:52:04.737] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 10:52:04 CST 2017]; root of context hierarchy
[2017-12-21 10:52:04.780] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 10:52:04.869] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 10:52:04.893] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 10:52:05.169] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 10:52:05.267] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 10:52:05.324] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.373] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.417] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:52:05.417] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:52:05.422] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.423] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.426] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:52:05.427] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:52:05.428] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.428] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:52:05.431] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:52:05.431] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:52:05.436] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:52:05.440] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:52:05.440] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 10:52:05.487] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:52:05.489] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:52:05.489] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:52:05.490] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:52:05.490] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:52:05.490] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:52:05.491] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:52:05.491] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:52:05.491] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:52:05.491] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:52:05.492] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:52:05.492] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:52:05.498] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 47
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 47
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 47
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:52:05.502] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:52:05.508] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:52:05.508] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:52:05.509] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:52:37.053] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 10:52:37.062] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 10:52:37.063] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 10:52:37.063] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 10:52:37.173] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 10:52:37.178] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 10:52:37.194] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:52:37.420] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:52:37.431] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:52:37.433] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:52:37.433] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:52:37.457] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:52:37.460] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:52:37.469] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:52:37.653] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:52:37.653] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 10:52:37.730] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:52:37.734] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 180] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[2017-12-21 10:52:37.746] [WARN ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 188] - The configuration 'group.id' was supplied but isn't a known config.
[2017-12-21 10:52:37.747] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:52:37.747] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:52:37.773] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 10:52:37.773] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-0@16
[2017-12-21 10:52:37.774] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:52:37.774] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 10:52:37.774] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:52:37.789] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:52:37.791] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:52:37.796] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:52:37.797] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:52:37.797] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:52:37.801] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:52:37.803] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:52:37.809] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:52:37.810] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:53:23.028] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:53:23.031] [INFO ] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 689] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[2017-12-21 10:53:23.740] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:53:23.740] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:53:23.931] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:53:28.947] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 10:53:29.029] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 10:53:29 CST 2017]; root of context hierarchy
[2017-12-21 10:53:29.080] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 10:53:29.172] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 10:53:29.201] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 10:53:29.271] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 10:53:29.272] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 10:53:29.289] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 10:53:29.291] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 10:53:29.292] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 10:53:29.293] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 10:53:29.294] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 10:53:29.294] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 10:53:29.294] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 10:53:29.295] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 10:53:29.296] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 10:53:29.296] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 10:53:29.297] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 10:53:29.297] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 10:53:29.298] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 10:53:29.299] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 10:53:29.316] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 10:53:29.317] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 10:53:29.319] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 10:53:29.547] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 10:53:29.588] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20107 (auto-detected)
[2017-12-21 10:53:29.591] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 10:53:29.592] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 10:53:29.594] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 10:53:29.595] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 10:53:29.598] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 10:53:29.612] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 10:53:29.612] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 10:53:29.641] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 10:53:29.642] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 10:53:29.642] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 10:53:29.643] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 10:53:29.643] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 10:53:29.643] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 10:53:29.644] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 10:53:29.644] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 10:53:29.644] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 10:53:29.644] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 10:53:29.645] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 10:53:29.655] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 10:53:29.655] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 10:53:29.656] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 10:53:29.678] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0xfcea9e38] REGISTERED
[2017-12-21 10:53:29.679] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0xfcea9e38] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 10:53:29.683] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 10:53:29.684] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0xfcea9e38, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 10:53:29.758] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.759] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 607] - Starting the Kafka consumer
[2017-12-21 10:53:29.832] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.841] [DEBUG] [main] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.2.201:9092 (id: -1 rack: null), 192.168.2.192:9092 (id: -3 rack: null), 192.168.2.202:9092 (id: -2 rack: null)], partitions = [])
[2017-12-21 10:53:29.851] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-closed:
[2017-12-21 10:53:29.852] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-created:
[2017-12-21 10:53:29.853] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent-received:
[2017-12-21 10:53:29.853] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent:
[2017-12-21 10:53:29.856] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-received:
[2017-12-21 10:53:29.857] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name select-time:
[2017-12-21 10:53:29.857] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name io-time:
[2017-12-21 10:53:29.873] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name heartbeat-latency
[2017-12-21 10:53:29.873] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name join-latency
[2017-12-21 10:53:29.874] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name sync-latency
[2017-12-21 10:53:29.876] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name commit-latency
[2017-12-21 10:53:29.882] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-fetched
[2017-12-21 10:53:29.882] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-fetched
[2017-12-21 10:53:29.883] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-latency
[2017-12-21 10:53:29.883] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-lag
[2017-12-21 10:53:29.883] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-throttle-time
[2017-12-21 10:53:29.885] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:53:29.885] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:53:29.886] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 711] - Kafka consumer created
[2017-12-21 10:53:29.887] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 882] - Subscribed to pattern: connection-test
[2017-12-21 10:53:29.890] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 548] - Sending GroupCoordinator request for group 0 to broker 192.168.2.201:9092 (id: -1 rack: null)
[2017-12-21 10:53:29.891] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.891] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 607] - Starting the Kafka consumer
[2017-12-21 10:53:29.891] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.892] [DEBUG] [main] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.2.201:9092 (id: -1 rack: null), 192.168.2.192:9092 (id: -3 rack: null), 192.168.2.202:9092 (id: -2 rack: null)], partitions = [])
[2017-12-21 10:53:29.892] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-closed:
[2017-12-21 10:53:29.892] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-created:
[2017-12-21 10:53:29.893] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent-received:
[2017-12-21 10:53:29.893] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent:
[2017-12-21 10:53:29.893] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-received:
[2017-12-21 10:53:29.893] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name select-time:
[2017-12-21 10:53:29.894] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name io-time:
[2017-12-21 10:53:29.894] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name heartbeat-latency
[2017-12-21 10:53:29.894] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name join-latency
[2017-12-21 10:53:29.895] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name sync-latency
[2017-12-21 10:53:29.895] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name commit-latency
[2017-12-21 10:53:29.895] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-fetched
[2017-12-21 10:53:29.896] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-fetched
[2017-12-21 10:53:29.896] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-latency
[2017-12-21 10:53:29.896] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-lag
[2017-12-21 10:53:29.897] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-throttle-time
[2017-12-21 10:53:29.897] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:53:29.897] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:53:29.897] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 711] - Kafka consumer created
[2017-12-21 10:53:29.897] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 882] - Subscribed to pattern: connection-test
[2017-12-21 10:53:29.898] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 548] - Sending GroupCoordinator request for group 0 to broker 192.168.2.202:9092 (id: -2 rack: null)
[2017-12-21 10:53:29.898] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.898] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 607] - Starting the Kafka consumer
[2017-12-21 10:53:29.899] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:53:29.899] [DEBUG] [main] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.2.202:9092 (id: -2 rack: null), 192.168.2.192:9092 (id: -3 rack: null), 192.168.2.201:9092 (id: -1 rack: null)], partitions = [])
[2017-12-21 10:53:29.900] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-closed:
[2017-12-21 10:53:29.900] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-created:
[2017-12-21 10:53:29.900] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent-received:
[2017-12-21 10:53:29.900] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent:
[2017-12-21 10:53:29.901] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-received:
[2017-12-21 10:53:29.901] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name select-time:
[2017-12-21 10:53:29.901] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name io-time:
[2017-12-21 10:53:29.902] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name heartbeat-latency
[2017-12-21 10:53:29.902] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name join-latency
[2017-12-21 10:53:29.903] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name sync-latency
[2017-12-21 10:53:29.903] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name commit-latency
[2017-12-21 10:53:29.903] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-fetched
[2017-12-21 10:53:29.904] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-fetched
[2017-12-21 10:53:29.904] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-latency
[2017-12-21 10:53:29.904] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-lag
[2017-12-21 10:53:29.904] [DEBUG] [main] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name fetch-throttle-time
[2017-12-21 10:53:29.905] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:53:29.905] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:53:29.905] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 711] - Kafka consumer created
[2017-12-21 10:53:29.905] [DEBUG] [main] [org.apache.kafka.clients.consumer.KafkaConsumer : 882] - Subscribed to pattern: connection-test
[2017-12-21 10:53:29.905] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 548] - Sending GroupCoordinator request for group 0 to broker 192.168.2.202:9092 (id: -2 rack: null)
[2017-12-21 10:53:29.907] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -2 at 192.168.2.202:9092.
[2017-12-21 10:53:29.907] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -1 at 192.168.2.201:9092.
[2017-12-21 10:53:29.907] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -2 at 192.168.2.202:9092.
[2017-12-21 10:53:29.909] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:53:29.912] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:53:29.912] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 10:53:29.919] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-sent
[2017-12-21 10:53:29.919] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-sent
[2017-12-21 10:53:29.919] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-sent
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-received
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-received
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-received
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.latency
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.latency
[2017-12-21 10:53:29.920] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.latency
[2017-12-21 10:53:29.923] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -2
[2017-12-21 10:53:29.924] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node -2.  Fetching API versions.
[2017-12-21 10:53:29.924] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node -2.
[2017-12-21 10:53:29.925] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -2
[2017-12-21 10:53:29.925] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node -2.  Fetching API versions.
[2017-12-21 10:53:29.925] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node -2.
[2017-12-21 10:53:29.927] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.201 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:207)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.928] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -1 disconnected.
[2017-12-21 10:53:29.929] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient : 487] - Cancelled GROUP_COORDINATOR request {api_key=10,api_version=0,correlation_id=0,client_id=consumer-1} with correlation id 0 due to node -1 being disconnected
[2017-12-21 10:53:29.930] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 215] - Coordinator discovery failed for group 0, refreshing metadata
[2017-12-21 10:53:29.930] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -3 for sending metadata request
[2017-12-21 10:53:29.930] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -3 at 192.168.2.192:9092.
[2017-12-21 10:53:29.931] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-sent
[2017-12-21 10:53:29.931] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-received
[2017-12-21 10:53:29.931] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.latency
[2017-12-21 10:53:29.932] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.192 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:203)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:138)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:216)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.932] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -3 disconnected.
[2017-12-21 10:53:29.932] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -2 for sending metadata request
[2017-12-21 10:53:29.932] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -2 at 192.168.2.202:9092.
[2017-12-21 10:53:29.933] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-sent
[2017-12-21 10:53:29.933] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-received
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -1 for sending metadata request
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -1 for sending metadata request
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.latency
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -1 at 192.168.2.201:9092.
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -1 at 192.168.2.201:9092.
[2017-12-21 10:53:29.934] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -2
[2017-12-21 10:53:29.935] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node -2.  Fetching API versions.
[2017-12-21 10:53:29.935] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node -2.
[2017-12-21 10:53:29.937] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-sent
[2017-12-21 10:53:29.937] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-sent
[2017-12-21 10:53:29.937] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-received
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-received
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.latency
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.latency
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.201 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:207)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.201 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:207)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.938] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -1 disconnected.
[2017-12-21 10:53:29.939] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -1 disconnected.
[2017-12-21 10:53:29.939] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -3 for sending metadata request
[2017-12-21 10:53:29.939] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -3 for sending metadata request
[2017-12-21 10:53:29.939] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -3 at 192.168.2.192:9092.
[2017-12-21 10:53:29.939] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -3 at 192.168.2.192:9092.
[2017-12-21 10:53:29.953] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node -2: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.953] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node -2: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.953] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node -2: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.954] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 751] - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -2
[2017-12-21 10:53:29.954] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 751] - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -2
[2017-12-21 10:53:29.954] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 751] - Sending metadata request (type=MetadataRequest, topics=<ALL>) to node -2
[2017-12-21 10:53:29.954] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-sent
[2017-12-21 10:53:29.954] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-sent
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-received
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-received
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.latency
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.latency
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.192 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:207)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.192 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:226)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:207)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:193)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:275)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:53:29.955] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -3 disconnected.
[2017-12-21 10:53:29.956] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -3 disconnected.
[2017-12-21 10:53:29.959] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 2 to Cluster(id = J2DWiP1xS5W5b5aM3VFe5g, nodes = [192.168.2.202:9092 (id: 1 rack: null)], partitions = [Partition(topic = connection-test, partition = 0, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 2, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 1, leader = 1, replicas = [0,1,2], isr = [1])])
[2017-12-21 10:53:29.959] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 2 to Cluster(id = J2DWiP1xS5W5b5aM3VFe5g, nodes = [192.168.2.202:9092 (id: 1 rack: null)], partitions = [Partition(topic = connection-test, partition = 0, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 2, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 1, leader = 1, replicas = [0,1,2], isr = [1])])
[2017-12-21 10:53:29.959] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 2 to Cluster(id = J2DWiP1xS5W5b5aM3VFe5g, nodes = [192.168.2.202:9092 (id: 1 rack: null)], partitions = [Partition(topic = connection-test, partition = 0, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 2, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 1, leader = 1, replicas = [0,1,2], isr = [1])])
[2017-12-21 10:53:29.960] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 548] - Sending GroupCoordinator request for group 0 to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:29.960] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 1 at 192.168.2.202:9092.
[2017-12-21 10:53:29.961] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 559] - Received GroupCoordinator response ClientResponse(receivedTimeMs=1513824809960, latencyMs=55, disconnected=false, requestHeader={api_key=10,api_version=0,correlation_id=0,client_id=consumer-3}, responseBody={error_code=0,coordinator={node_id=1,host=192.168.2.202,port=9092}}) for group 0
[2017-12-21 10:53:29.961] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 559] - Received GroupCoordinator response ClientResponse(receivedTimeMs=1513824809960, latencyMs=55, disconnected=false, requestHeader={api_key=10,api_version=0,correlation_id=0,client_id=consumer-2}, responseBody={error_code=0,coordinator={node_id=1,host=192.168.2.202,port=9092}}) for group 0
[2017-12-21 10:53:29.961] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:53:29.961] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:53:29.961] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 2147483646 at 192.168.2.202:9092.
[2017-12-21 10:53:29.961] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-sent
[2017-12-21 10:53:29.961] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 2147483646 at 192.168.2.202:9092.
[2017-12-21 10:53:29.962] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-received
[2017-12-21 10:53:29.962] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.latency
[2017-12-21 10:53:29.962] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
[2017-12-21 10:53:29.962] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 1.  Fetching API versions.
[2017-12-21 10:53:29.963] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 1.
[2017-12-21 10:53:29.963] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:53:29.963] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:53:29.963] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 869] - Heartbeat thread for group 0 started
[2017-12-21 10:53:29.963] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 869] - Heartbeat thread for group 0 started
[2017-12-21 10:53:29.963] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:53:29.963] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:53:29.963] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:53:29.964] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:53:29.964] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.965] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 559] - Received GroupCoordinator response ClientResponse(receivedTimeMs=1513824809965, latencyMs=5, disconnected=false, requestHeader={api_key=10,api_version=0,correlation_id=3,client_id=consumer-1}, responseBody={error_code=0,coordinator={node_id=1,host=192.168.2.202,port=9092}}) for group 0
[2017-12-21 10:53:29.965] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:53:29.965] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 2147483646 at 192.168.2.202:9092.
[2017-12-21 10:53:29.965] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 415] - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@54423c41)) to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:29.965] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 415] - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@494546eb)) to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:29.966] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:53:29.966] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 869] - Heartbeat thread for group 0 started
[2017-12-21 10:53:29.966] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:53:29.966] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:53:29.966] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 415] - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@70c8da02)) to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:29.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-sent
[2017-12-21 10:53:29.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-sent
[2017-12-21 10:53:29.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-sent
[2017-12-21 10:53:29.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-received
[2017-12-21 10:53:29.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-received
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.bytes-received
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.latency
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.latency
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-2147483646.latency
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 2147483646.  Fetching API versions.
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 2147483646
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 2147483646.  Fetching API versions.
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 2147483646.
[2017-12-21 10:53:29.968] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 2147483646.  Fetching API versions.
[2017-12-21 10:53:29.969] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 2147483646.
[2017-12-21 10:53:29.969] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 2147483646.
[2017-12-21 10:53:29.970] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 2147483646: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.970] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 2147483646: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.970] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 2147483646: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.972] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 425] - Received successful JoinGroup response for group 0: {error_code=0,generation_id=49,group_protocol=range,leader_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,members=[{member_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=27 cap=27]}]}
[2017-12-21 10:53:29.972] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 336] - Performing assignment for group 0 using strategy range with subscriptions {consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77=Subscription(topics=[connection-test])}
[2017-12-21 10:53:29.973] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 375] - Finished assignment for group 0: {consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77=Assignment(partitions=[connection-test-0, connection-test-1, connection-test-2])}
[2017-12-21 10:53:29.973] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 493] - Sending leader SyncGroup for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=0, generationId=49, memberId=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77, groupAssignment=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77)
[2017-12-21 10:53:29.975] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 522] - SyncGroup for group 0 failed due to coordinator rebalance
[2017-12-21 10:53:29.975] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:53:29.975] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 415] - Sending JoinGroup ((type: JoinGroupRequest, groupId=0, sessionTimeout=15000, rebalanceTimeout=300000, memberId=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@1315ef90)) to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 425] - Received successful JoinGroup response for group 0: {error_code=0,generation_id=50,group_protocol=range,leader_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_id=consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f,members=[]}
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 425] - Received successful JoinGroup response for group 0: {error_code=0,generation_id=50,group_protocol=range,leader_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_id=consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70,members=[]}
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 425] - Received successful JoinGroup response for group 0: {error_code=0,generation_id=50,group_protocol=range,leader_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,members=[{member_id=consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=27 cap=187]},{member_id=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=27 cap=107]},{member_id=consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=27 cap=27]}]}
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 480] - Sending follower SyncGroup for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=0, generationId=50, memberId=consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f, groupAssignment=)
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 480] - Sending follower SyncGroup for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=0, generationId=50, memberId=consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70, groupAssignment=)
[2017-12-21 10:53:29.977] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 336] - Performing assignment for group 0 using strategy range with subscriptions {consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70=Subscription(topics=[connection-test]), consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f=Subscription(topics=[connection-test]), consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77=Subscription(topics=[connection-test])}
[2017-12-21 10:53:29.978] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 375] - Finished assignment for group 0: {consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70=Assignment(partitions=[connection-test-1]), consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f=Assignment(partitions=[connection-test-2]), consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77=Assignment(partitions=[connection-test-0])}
[2017-12-21 10:53:29.978] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 493] - Sending leader SyncGroup for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null): (type=SyncGroupRequest, groupId=0, generationId=50, memberId=consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77, groupAssignment=consumer-2-fa59a8ad-6cf9-489a-aa33-1a8b04c0ee70,consumer-3-360eed5b-b543-4d02-8487-85b1d4da981f,consumer-1-1508b2a2-d9ee-46f9-a19e-7ce9c2b6fe77)
[2017-12-21 10:53:29.979] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 50
[2017-12-21 10:53:29.979] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 50
[2017-12-21 10:53:29.979] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 50
[2017-12-21 10:53:29.980] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:53:29.980] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:53:29.981] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:53:29.981] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 800] - Group 0 fetching committed offsets for partitions: [connection-test-1]
[2017-12-21 10:53:29.981] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 800] - Group 0 fetching committed offsets for partitions: [connection-test-2]
[2017-12-21 10:53:29.981] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 800] - Group 0 fetching committed offsets for partitions: [connection-test-0]
[2017-12-21 10:53:29.984] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 250] - Resetting offset for partition connection-test-1 to the committed offset 21
[2017-12-21 10:53:29.984] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 250] - Resetting offset for partition connection-test-2 to the committed offset 19
[2017-12-21 10:53:29.984] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 250] - Resetting offset for partition connection-test-0 to the committed offset 17
[2017-12-21 10:53:29.986] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 732] - Group 0 committed offset 19 for partition connection-test-2
[2017-12-21 10:53:29.986] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 732] - Group 0 committed offset 21 for partition connection-test-1
[2017-12-21 10:53:29.986] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 732] - Group 0 committed offset 17 for partition connection-test-0
[2017-12-21 10:53:29.987] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:53:29.987] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:53:29.988] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:53:29.989] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:29.989] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:29.989] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:29.989] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 1 at 192.168.2.202:9092.
[2017-12-21 10:53:29.989] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 1 at 192.168.2.202:9092.
[2017-12-21 10:53:29.990] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-sent
[2017-12-21 10:53:29.990] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-sent
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-received
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-received
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.latency
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.latency
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
[2017-12-21 10:53:29.991] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 66608, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
[2017-12-21 10:53:29.992] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 1.  Fetching API versions.
[2017-12-21 10:53:29.992] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 1.  Fetching API versions.
[2017-12-21 10:53:29.992] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 1.
[2017-12-21 10:53:29.992] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 1.
[2017-12-21 10:53:29.993] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:29.993] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:53:30.502] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.bytes-fetched
[2017-12-21 10:53:30.502] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.bytes-fetched
[2017-12-21 10:53:30.502] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.bytes-fetched
[2017-12-21 10:53:30.503] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.records-fetched
[2017-12-21 10:53:30.503] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.records-fetched
[2017-12-21 10:53:30.503] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.records-fetched
[2017-12-21 10:53:30.504] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connection-test-0.records-lag
[2017-12-21 10:53:30.504] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connection-test-1.records-lag
[2017-12-21 10:53:30.504] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connection-test-2.records-lag
[2017-12-21 10:53:30.504] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:30.505] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:30.505] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.007] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.007] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.510] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.510] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:31.511] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.012] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.012] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.013] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.514] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.515] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:32.515] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.001] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:33.004] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:33.008] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:33.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:33.017] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.017] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.017] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.021] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:33.022] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:33.521] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.521] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:33.521] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.024] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.024] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.024] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.527] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.527] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:34.527] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.029] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.029] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.029] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.532] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.532] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:35.532] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.014] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:36.015] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:36.020] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:36.021] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:36.029] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:36.030] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:36.034] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.035] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.035] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.536] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.536] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:36.537] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.038] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.038] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.039] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.541] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.541] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:37.541] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.043] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.043] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.043] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.545] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.545] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:38.545] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.026] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:39.028] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:39.029] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:39.030] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:39.038] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:39.040] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:39.047] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.047] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.047] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.550] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.550] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:39.550] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.052] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.053] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.053] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.555] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.555] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:40.556] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.058] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.058] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.058] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.561] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.561] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:41.561] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.030] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:42.032] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:42.042] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:42.044] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:42.044] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:42.045] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:42.071] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.071] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.071] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.574] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.574] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:42.574] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.077] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.077] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.077] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.579] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.579] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:43.579] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.081] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.081] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.081] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.583] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.583] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:44.583] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.034] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:45.036] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:45.048] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:45.048] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:45.050] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:45.050] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:45.085] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.085] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.085] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.587] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.587] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:45.587] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.089] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.089] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.089] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.591] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.591] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:46.591] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.093] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.093] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.093] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.595] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.595] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:47.595] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.039] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:48.041] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:48.057] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:48.057] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:48.059] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:48.059] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:48.097] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.097] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.097] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.599] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.599] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:48.599] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.102] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.102] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.102] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.604] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.605] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:49.605] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.107] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.107] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.107] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.609] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.609] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:50.609] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.050] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:51.052] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:51.068] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:51.068] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:51.069] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:51.070] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:51.111] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.111] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.111] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.613] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.613] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:51.613] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.114] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.115] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.115] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.616] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.617] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:52.617] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.118] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.119] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.119] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.620] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.621] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:53.621] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.058] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:54.059] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:54.076] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:54.077] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:54.081] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:54.083] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:54.122] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.122] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.122] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.625] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.625] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:54.625] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.127] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.129] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.130] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.630] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.632] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:55.632] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.132] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.134] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.134] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.635] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.635] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:56.635] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.068] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:57.070] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:57.086] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:57.087] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:57.094] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:53:57.097] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:53:57.137] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.137] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.138] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.640] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.640] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:57.640] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.142] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.142] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.142] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.644] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.645] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:58.646] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.147] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.649] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.649] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:53:59.649] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.073] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:00.074] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:00.095] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:00.095] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:00.096] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:00.096] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:00.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.653] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.653] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:00.653] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.155] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.155] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.155] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.658] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.658] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:01.658] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.161] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.161] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.161] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.663] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.663] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:02.663] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.082] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:03.084] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:03.105] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:03.105] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:03.106] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:03.106] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:03.165] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.165] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.165] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.666] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.666] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:03.666] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.168] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.168] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.168] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.670] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.670] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:04.670] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.173] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.173] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.173] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.676] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.676] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:05.676] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.087] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:06.089] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:06.113] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:06.113] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:06.114] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:06.114] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:06.178] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.178] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.178] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.680] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.680] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:06.680] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.027] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 10:54:07.029] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 10:54:07.050] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 10:54:07.052] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 10:54:07.053] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 10:54:07.054] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 10:54:07.055] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 10:54:07.055] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 10:54:07.056] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 10:54:07.056] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 10:54:07.057] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 10:54:07.058] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 10:54:07.058] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 10:54:07.059] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 10:54:07.059] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 10:54:07.060] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 10:54:07.077] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 10:54:07.078] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 10:54:07.080] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 10:54:07.121] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20114 (auto-detected)
[2017-12-21 10:54:07.123] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 10:54:07.123] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 10:54:07.125] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 10:54:07.126] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 10:54:07.128] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 10:54:07.142] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 10:54:07.142] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 10:54:07.166] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 10:54:07.166] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 10:54:07.166] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 10:54:07.167] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 10:54:07.167] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 10:54:07.167] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 10:54:07.167] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 10:54:07.167] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 10:54:07.168] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 10:54:07.168] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 10:54:07.168] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 10:54:07.176] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 10:54:07.176] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 10:54:07.176] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 10:54:07.181] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.181] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.181] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.248] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 10:54:07.249] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0xfcea9e38, L:/0:0:0:0:0:0:0:0:10010] RECEIVED: [id: 0x5c9b106b, L:/127.0.0.1:10010 - R:/127.0.0.1:53490]
[2017-12-21 10:54:07.257] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 10:54:07.258] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 10:54:07.258] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 10:54:07.359] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 10:54:07.363] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 10:54:07.364] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 10:54:07.364] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 10:54:07.364] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 10:54:07.365] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 10:54:07.377] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 10:54:07.379] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@148136a8
[2017-12-21 10:54:07.381] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:54:07.608] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:54:07.623] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:54:07.629] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:54:07.629] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:54:07.637] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 10:54:07.637] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 10:54:07.637] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 10:54:07.637] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 10:54:07.649] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 10:54:07.650] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@4b72525d
[2017-12-21 10:54:07.654] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:54:07.656] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:54:07.657] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:53490, package length = 186
[2017-12-21 10:54:07.664] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:54:07.712] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.712] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.712] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.830] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:54:07.830] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 10:54:07.900] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:07.904] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 180] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[2017-12-21 10:54:07.908] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bufferpool-wait-time
[2017-12-21 10:54:07.910] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name buffer-exhausted-records
[2017-12-21 10:54:07.910] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 1 to Cluster(id = null, nodes = [192.168.2.201:9092 (id: -1 rack: null), 192.168.2.202:9092 (id: -2 rack: null), 192.168.2.192:9092 (id: -3 rack: null)], partitions = [])
[2017-12-21 10:54:07.911] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-closed:
[2017-12-21 10:54:07.911] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name connections-created:
[2017-12-21 10:54:07.911] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent-received:
[2017-12-21 10:54:07.911] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-sent:
[2017-12-21 10:54:07.912] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name bytes-received:
[2017-12-21 10:54:07.912] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name select-time:
[2017-12-21 10:54:07.912] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name io-time:
[2017-12-21 10:54:07.914] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name batch-size
[2017-12-21 10:54:07.914] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name compression-rate
[2017-12-21 10:54:07.915] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name queue-time
[2017-12-21 10:54:07.915] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name request-time
[2017-12-21 10:54:07.915] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name produce-throttle-time
[2017-12-21 10:54:07.915] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name records-per-request
[2017-12-21 10:54:07.915] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name record-retries
[2017-12-21 10:54:07.916] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name errors
[2017-12-21 10:54:07.916] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name record-size-max
[2017-12-21 10:54:07.917] [WARN ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 188] - The configuration 'group.id' was supplied but isn't a known config.
[2017-12-21 10:54:07.917] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.producer.internals.Sender : 121] - Starting Kafka producer I/O thread.
[2017-12-21 10:54:07.918] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:54:07.918] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:54:07.918] [DEBUG] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.KafkaProducer : 336] - Kafka producer started
[2017-12-21 10:54:07.920] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -2 for sending metadata request
[2017-12-21 10:54:07.921] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -2 at 192.168.2.202:9092.
[2017-12-21 10:54:07.922] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-sent
[2017-12-21 10:54:07.922] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.bytes-received
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--2.latency
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node -2
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node -2.  Fetching API versions.
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node -2.
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -3 for sending metadata request
[2017-12-21 10:54:07.923] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -3 at 192.168.2.192:9092.
[2017-12-21 10:54:07.924] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-sent
[2017-12-21 10:54:07.926] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.bytes-received
[2017-12-21 10:54:07.926] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--3.latency
[2017-12-21 10:54:07.926] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.192 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:225)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:126)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:54:07.927] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -3 disconnected.
[2017-12-21 10:54:07.927] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 767] - Initialize connection to node -1 for sending metadata request
[2017-12-21 10:54:07.927] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node -1 at 192.168.2.201:9092.
[2017-12-21 10:54:07.927] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node -2: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:54:07.928] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 751] - Sending metadata request (type=MetadataRequest, topics=connection-test) to node -2
[2017-12-21 10:54:07.928] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-sent
[2017-12-21 10:54:07.928] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.bytes-received
[2017-12-21 10:54:07.928] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node--1.latency
[2017-12-21 10:54:07.928] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.network.Selector : 375] - Connection with /192.168.2.201 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:51)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:81)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:335)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:303)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:349)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:225)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:126)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 10:54:07.929] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 570] - Node -1 disconnected.
[2017-12-21 10:54:07.930] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.Metadata : 244] - Updated cluster metadata version 2 to Cluster(id = J2DWiP1xS5W5b5aM3VFe5g, nodes = [192.168.2.202:9092 (id: 1 rack: null)], partitions = [Partition(topic = connection-test, partition = 0, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 2, leader = 1, replicas = [0,1,2], isr = [1]), Partition(topic = connection-test, partition = 1, leader = 1, replicas = [0,1,2], isr = [1])])
[2017-12-21 10:54:07.939] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 627] - Initiating connection to node 1 at 192.168.2.202:9092.
[2017-12-21 10:54:07.940] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-sent
[2017-12-21 10:54:07.941] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.bytes-received
[2017-12-21 10:54:07.941] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name node-1.latency
[2017-12-21 10:54:07.941] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.network.Selector : 339] - Created socket with SO_RCVBUF = 33304, SO_SNDBUF = 131768, SO_TIMEOUT = 0 to node 1
[2017-12-21 10:54:07.941] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 590] - Completed connection to node 1.  Fetching API versions.
[2017-12-21 10:54:07.941] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 603] - Initiating API versions fetch from node 1.
[2017-12-21 10:54:07.942] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.NetworkClient : 558] - Recorded API versions for node 1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], Offsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], GroupCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0])
[2017-12-21 10:54:07.943] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.records-per-batch
[2017-12-21 10:54:07.943] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.bytes
[2017-12-21 10:54:07.943] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.compression-rate
[2017-12-21 10:54:07.943] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.record-retries
[2017-12-21 10:54:07.943] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 335] - Added sensor with name topic.connection-test.record-errors
[2017-12-21 10:54:07.947] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 526] - Ignoring fetched records for connection-test-0 at offset 17 since the current position is 18
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 10:54:07.948] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:07.948] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-0@17
[2017-12-21 10:54:07.949] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 10:54:07.950] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:07.950] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:07.965] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:54:07.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 732] - Group 0 committed offset 18 for partition connection-test-0
[2017-12-21 10:54:07.967] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:54:07.973] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:54:07.973] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:54:07.973] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:54:07.977] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:54:07.979] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:54:07.980] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 10:54:07.986] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:54:07.987] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:54:08.214] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:08.214] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:08.448] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:08.716] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:08.716] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:08.950] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.091] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:09.093] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:09.122] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:09.122] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:09.123] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:09.123] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:09.219] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.219] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.452] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.721] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.721] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:09.953] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.223] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.223] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.455] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.724] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.724] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:10.957] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.225] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.225] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.459] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.746] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.746] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:11.967] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.094] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:12.096] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:12.131] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:12.131] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:12.133] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:12.133] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:12.248] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.248] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.470] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.751] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.751] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:12.972] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.253] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.253] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.473] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.756] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.756] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:13.975] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.258] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.258] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.477] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.761] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.761] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:14.979] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.097] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:15.098] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:15.137] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:15.137] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 704] - Sending Heartbeat request for group 0 to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null)
[2017-12-21 10:54:15.138] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:15.138] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 717] - Received successful Heartbeat response for group 0
[2017-12-21 10:54:15.263] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.263] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.481] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.765] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.765] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:15.983] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.267] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.267] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.485] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.768] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-1] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.768] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-2] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:16.987] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.Fetcher : 180] - Sending fetch for partitions [connection-test-0] to broker 192.168.2.202:9092 (id: 1 rack: null)
[2017-12-21 10:54:17.006] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:54:17.008] [INFO ] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 689] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[2017-12-21 10:54:17.009] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.producer.internals.Sender : 132] - Beginning shutdown of Kafka producer I/O thread, sending remaining records.
[2017-12-21 10:54:17.011] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-closed:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-created:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent-received:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-received:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name select-time:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name io-time:
[2017-12-21 10:54:17.012] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-sent
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-received
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.latency
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-sent
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-received
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.latency
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-sent
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-received
[2017-12-21 10:54:17.013] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.latency
[2017-12-21 10:54:17.014] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-sent
[2017-12-21 10:54:17.014] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-received
[2017-12-21 10:54:17.014] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.latency
[2017-12-21 10:54:17.014] [DEBUG] [kafka-producer-network-thread | producer-1] [org.apache.kafka.clients.producer.internals.Sender : 155] - Shutdown of Kafka producer I/O thread has completed.
[2017-12-21 10:54:17.014] [DEBUG] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 732] - The Kafka producer has closed.
[2017-12-21 10:54:17.145] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 899] - Unsubscribed all topics or patterns and assigned partitions
[2017-12-21 10:54:17.145] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 899] - Unsubscribed all topics or patterns and assigned partitions
[2017-12-21 10:54:17.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connection-test-2.records-lag
[2017-12-21 10:54:17.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 677] - Sending LeaveGroup request to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0
[2017-12-21 10:54:17.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connection-test-1.records-lag
[2017-12-21 10:54:17.146] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 677] - Sending LeaveGroup request to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0
[2017-12-21 10:54:17.148] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 693] - LeaveGroup request for group 0 returned successfully
[2017-12-21 10:54:17.148] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 693] - LeaveGroup request for group 0 returned successfully
[2017-12-21 10:54:17.148] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 947] - Heartbeat thread for group 0 has closed
[2017-12-21 10:54:17.148] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 947] - Heartbeat thread for group 0 has closed
[2017-12-21 10:54:17.149] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-closed:
[2017-12-21 10:54:17.149] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-closed:
[2017-12-21 10:54:17.149] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-created:
[2017-12-21 10:54:17.149] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-created:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent-received:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent-received:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-received:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-received:
[2017-12-21 10:54:17.150] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name select-time:
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name select-time:
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name io-time:
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name io-time:
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-sent
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-sent
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-received
[2017-12-21 10:54:17.151] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-received
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.latency
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.latency
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-sent
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-received
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-sent
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.latency
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-received
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-sent
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.latency
[2017-12-21 10:54:17.152] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-received
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-sent
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.latency
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-received
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-sent
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.latency
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-received
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-sent
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.latency
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-received
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-sent
[2017-12-21 10:54:17.153] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.latency
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-received
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-sent
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.latency
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-received
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 1569] - The Kafka consumer has closed.
[2017-12-21 10:54:17.154] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.latency
[2017-12-21 10:54:17.154] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 1569] - The Kafka consumer has closed.
[2017-12-21 10:54:17.154] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:54:18.002] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 899] - Unsubscribed all topics or patterns and assigned partitions
[2017-12-21 10:54:18.003] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connection-test-0.records-lag
[2017-12-21 10:54:18.003] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 677] - Sending LeaveGroup request to coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0
[2017-12-21 10:54:18.005] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 693] - LeaveGroup request for group 0 returned successfully
[2017-12-21 10:54:18.005] [DEBUG] [kafka-coordinator-heartbeat-thread | 0] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 947] - Heartbeat thread for group 0 has closed
[2017-12-21 10:54:18.005] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-closed:
[2017-12-21 10:54:18.006] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name connections-created:
[2017-12-21 10:54:18.006] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent-received:
[2017-12-21 10:54:18.006] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-sent:
[2017-12-21 10:54:18.006] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name bytes-received:
[2017-12-21 10:54:18.006] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name select-time:
[2017-12-21 10:54:18.007] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name io-time:
[2017-12-21 10:54:18.007] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-sent
[2017-12-21 10:54:18.007] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.bytes-received
[2017-12-21 10:54:18.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--1.latency
[2017-12-21 10:54:18.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-sent
[2017-12-21 10:54:18.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.bytes-received
[2017-12-21 10:54:18.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--3.latency
[2017-12-21 10:54:18.008] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-sent
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.bytes-received
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node--2.latency
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-sent
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.bytes-received
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-1.latency
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-sent
[2017-12-21 10:54:18.009] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.bytes-received
[2017-12-21 10:54:18.010] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.common.metrics.Metrics : 368] - Removed sensor with name node-2147483646.latency
[2017-12-21 10:54:18.010] [DEBUG] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.KafkaConsumer : 1569] - The Kafka consumer has closed.
[2017-12-21 10:54:18.010] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:54:45.508] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 10:54:45.587] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 10:54:45 CST 2017]; root of context hierarchy
[2017-12-21 10:54:45.630] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 10:54:45.718] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 10:54:45.745] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 10:54:45.814] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 10:54:45.815] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 10:54:45.831] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 10:54:45.834] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 10:54:45.836] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 10:54:45.836] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 10:54:45.837] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 10:54:45.838] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 10:54:45.838] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 10:54:45.839] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 10:54:45.840] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 10:54:45.841] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 10:54:45.842] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 10:54:45.842] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 10:54:45.843] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 10:54:45.844] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 10:54:45.860] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 10:54:45.861] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 10:54:45.863] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 10:54:46.041] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 10:54:46.074] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20121 (auto-detected)
[2017-12-21 10:54:46.076] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 10:54:46.076] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 10:54:46.078] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 10:54:46.079] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 10:54:46.082] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 10:54:46.094] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 10:54:46.094] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 10:54:46.120] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 10:54:46.120] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 10:54:46.120] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 10:54:46.121] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 10:54:46.121] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 10:54:46.121] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 10:54:46.121] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 10:54:46.122] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 10:54:46.122] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 10:54:46.122] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 10:54:46.122] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 10:54:46.132] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 10:54:46.132] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 10:54:46.133] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 10:54:46.150] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4700952f] REGISTERED
[2017-12-21 10:54:46.151] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4700952f] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 10:54:46.154] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 10:54:46.155] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4700952f, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 10:54:46.211] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.278] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.324] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:54:46.325] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:54:46.329] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.330] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.333] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:54:46.333] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:54:46.334] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.336] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 10:54:46.339] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:54:46.339] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:54:46.345] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:54:46.349] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 10:54:46.349] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 10:54:46.398] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:54:46.399] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:54:46.399] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 10:54:46.400] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:54:46.400] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:54:46.401] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:54:46.409] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 10:54:46.412] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 53
[2017-12-21 10:54:46.412] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 53
[2017-12-21 10:54:46.412] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 53
[2017-12-21 10:54:46.413] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 10:54:46.413] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 10:54:46.413] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 10:54:46.418] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 10:54:46.418] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 10:54:46.418] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 10:54:53.888] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 10:54:53.892] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 10:54:53.910] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 10:54:53.912] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 10:54:53.912] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 10:54:53.913] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 10:54:53.915] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 10:54:53.916] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 10:54:53.916] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 10:54:53.917] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 10:54:53.918] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 10:54:53.919] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 10:54:53.919] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 10:54:53.920] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 10:54:53.921] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 10:54:53.921] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 10:54:53.938] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 10:54:53.938] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 10:54:53.940] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 10:54:53.981] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20124 (auto-detected)
[2017-12-21 10:54:53.983] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 10:54:53.983] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 10:54:53.985] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 10:54:53.986] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 10:54:53.988] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 10:54:54.000] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 10:54:54.000] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 10:54:54.024] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 10:54:54.025] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 10:54:54.026] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 10:54:54.026] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 10:54:54.026] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 10:54:54.026] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 10:54:54.033] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 10:54:54.033] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 10:54:54.034] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 10:54:54.102] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 10:54:54.104] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4700952f, L:/0:0:0:0:0:0:0:0:10010] RECEIVED: [id: 0xf915d721, L:/127.0.0.1:10010 - R:/127.0.0.1:53517]
[2017-12-21 10:54:54.111] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 10:54:54.111] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 10:54:54.112] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 10:54:54.215] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 10:54:54.222] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 10:54:54.222] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 10:54:54.223] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 10:54:54.223] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 10:54:54.225] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 10:54:54.237] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 10:54:54.239] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@44d56d8e
[2017-12-21 10:54:54.242] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:54:54.452] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:54:54.463] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:54:54.466] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:54:54.466] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:54:54.476] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 10:54:54.476] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 10:54:54.476] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 10:54:54.477] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 10:54:54.488] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 10:54:54.489] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@787bd30e
[2017-12-21 10:54:54.494] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:54:54.499] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:54:54.500] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:53517, package length = 186
[2017-12-21 10:54:54.508] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:54:54.724] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:54:54.725] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 10:54:54.793] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:54.797] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 180] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[2017-12-21 10:54:54.807] [WARN ] [nioEventLoopGroup-3-1] [org.apache.kafka.clients.producer.ProducerConfig : 188] - The configuration 'group.id' was supplied but isn't a known config.
[2017-12-21 10:54:54.808] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 10:54:54.808] [INFO ] [nioEventLoopGroup-3-1] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 10:54:54.832] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 10:54:54.832] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 10:54:54.833] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 10:54:54.833] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 10:54:54.833] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 10:54:54.833] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:54.834] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-0@18
[2017-12-21 10:54:54.834] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:54.834] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 10:54:54.834] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 10:54:54.849] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 10:54:54.850] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 10:54:54.856] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 10:54:54.856] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 10:54:54.856] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 10:54:54.860] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 10:54:54.862] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 10:54:54.863] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 10:54:54.868] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 10:54:54.869] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 10:56:54.606] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 10:56:54.607] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 10:59:54.212] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 10:59:54.214] [INFO ] [Thread-1] [org.apache.kafka.clients.producer.KafkaProducer : 689] - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[2017-12-21 10:59:54.343] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:59:54.343] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 10:59:54.763] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:04:08.541] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 11:04:08.617] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 11:04:08 CST 2017]; root of context hierarchy
[2017-12-21 11:04:08.660] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 11:04:08.753] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 11:04:08.782] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 11:04:08.848] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:04:08.849] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:04:08.866] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:04:08.869] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:04:08.870] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:04:08.871] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:04:08.872] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:04:08.873] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:04:08.874] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:04:08.875] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:04:08.877] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:04:08.877] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:04:08.878] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:04:08.878] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:04:08.880] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:04:08.881] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:04:08.903] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:04:08.903] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:04:08.906] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:04:09.077] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 11:04:09.120] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20215 (auto-detected)
[2017-12-21 11:04:09.122] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:04:09.123] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:04:09.124] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:04:09.125] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:04:09.128] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:04:09.140] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:04:09.141] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:04:09.168] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:04:09.169] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:04:09.169] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:04:09.169] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:04:09.170] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:04:09.170] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:04:09.170] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:04:09.170] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:04:09.171] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:04:09.171] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:04:09.171] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:04:09.182] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:04:09.182] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:04:09.182] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:04:09.207] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x9d92c3f0] REGISTERED
[2017-12-21 11:04:09.208] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x9d92c3f0] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 11:04:09.211] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 11:04:09.212] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x9d92c3f0, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 11:04:09.268] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.323] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.366] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 11:04:09.366] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 11:04:09.370] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.371] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.375] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 11:04:09.375] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 11:04:09.376] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.377] [INFO ] [main] [org.apache.kafka.clients.consumer.ConsumerConfig : 180] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.2.201:9092, 192.168.2.202:9092, 192.168.2.192:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[2017-12-21 11:04:09.381] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 83] - Kafka version : 0.10.2.0
[2017-12-21 11:04:09.381] [INFO ] [main] [org.apache.kafka.common.utils.AppInfoParser : 84] - Kafka commitId : 576d93a8dc0cf421
[2017-12-21 11:04:09.387] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:04:09.390] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:04:09.391] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 11:04:09.431] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 11:04:09.433] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 11:04:09.433] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:04:09.433] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 11:04:09.434] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 11:04:09.434] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 573] - Discovered coordinator 192.168.2.202:9092 (id: 2147483646 rack: null) for group 0.
[2017-12-21 11:04:09.435] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 11:04:09.435] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 393] - Revoking previously assigned partitions [] for group 0
[2017-12-21 11:04:09.435] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:04:09.435] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:04:09.436] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 11:04:09.436] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 11:04:09.442] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 407] - (Re-)joining group 0
[2017-12-21 11:04:09.445] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 56
[2017-12-21 11:04:09.445] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 56
[2017-12-21 11:04:09.445] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator : 375] - Successfully joined group 0 with generation 56
[2017-12-21 11:04:09.446] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-1] for group 0
[2017-12-21 11:04:09.446] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-0] for group 0
[2017-12-21 11:04:09.446] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 252] - Setting newly assigned partitions [connection-test-2] for group 0
[2017-12-21 11:04:09.452] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 11:04:09.452] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:04:09.452] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 11:05:26.772] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 11:05:27.692] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:05:27.693] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:05:27.693] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:05:32.217] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 11:05:32.296] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 11:05:32 CST 2017]; root of context hierarchy
[2017-12-21 11:05:32.339] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 11:05:32.428] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 11:05:32.456] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 11:05:32.519] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:05:32.520] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:05:32.535] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:05:32.537] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:05:32.538] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:05:32.538] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:05:32.539] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:05:32.540] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:05:32.540] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:05:32.541] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:05:32.542] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:05:32.543] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:05:32.543] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:05:32.544] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:05:32.545] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:05:32.545] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:05:32.564] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:05:32.565] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:05:32.567] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:05:32.740] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 11:05:32.782] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20226 (auto-detected)
[2017-12-21 11:05:32.784] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:05:32.784] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:05:32.786] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:05:32.787] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:05:32.790] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:05:32.801] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:05:32.802] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:05:32.825] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:05:32.825] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:05:32.826] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:05:32.826] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:05:32.826] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:05:32.827] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:05:32.827] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:05:32.827] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:05:32.827] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:05:32.828] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:05:32.828] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:05:32.838] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:05:32.839] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:05:32.839] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:05:32.861] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x49825956] REGISTERED
[2017-12-21 11:05:32.862] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x49825956] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 11:05:32.865] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 11:05:32.866] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x49825956, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 11:05:33.020] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:05:33.023] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:05:33.024] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 11:05:33.072] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:05:33.072] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:05:33.073] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:05:33.089] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 11:05:33.089] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 11:05:33.090] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:05:48.648] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:05:48.651] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:05:48.670] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:05:48.673] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:05:48.674] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:05:48.675] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:05:48.676] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:05:48.677] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:05:48.677] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:05:48.679] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:05:48.680] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:05:48.680] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:05:48.681] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:05:48.682] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:05:48.683] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:05:48.683] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:05:48.703] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:05:48.704] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:05:48.706] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:05:48.760] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20230 (auto-detected)
[2017-12-21 11:05:48.764] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:05:48.764] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:05:48.766] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:05:48.768] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:05:48.771] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:05:48.788] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:05:48.789] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:05:48.821] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:05:48.822] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:05:48.822] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:05:48.822] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:05:48.823] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:05:48.823] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:05:48.823] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:05:48.824] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:05:48.824] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:05:48.825] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:05:48.825] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:05:48.837] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:05:48.838] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:05:48.838] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:05:48.926] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 11:05:48.935] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x49825956, L:/0:0:0:0:0:0:0:0:10010] RECEIVED: [id: 0xde24d588, L:/127.0.0.1:10010 - R:/127.0.0.1:53642]
[2017-12-21 11:05:48.944] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 11:05:48.944] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 11:05:48.944] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 11:05:49.130] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 11:05:49.135] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:05:49.135] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:05:49.135] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:05:49.136] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:05:49.138] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 11:05:49.153] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:05:49.155] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@148136a8
[2017-12-21 11:05:49.158] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:05:49.384] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:05:49.393] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:05:49.395] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:05:49.395] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:05:49.404] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:05:49.404] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:05:49.404] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:05:49.404] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:05:49.415] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:05:49.417] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@5c3d49e2
[2017-12-21 11:05:49.421] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:05:49.424] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:05:49.425] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:53642, package length = 186
[2017-12-21 11:05:49.433] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:05:49.591] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:05:49.591] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 11:05:49.666] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:05:49.708] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 11:05:49.709] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 11:05:49.709] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 11:05:49.710] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 11:05:49.710] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 11:05:49.710] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:05:49.710] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-0@19
[2017-12-21 11:05:49.711] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 11:05:49.711] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:05:49.711] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:05:49.728] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:05:49.729] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:05:49.734] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:05:49.734] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:05:49.734] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:05:49.738] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:05:49.741] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:05:49.741] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 11:05:49.747] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:05:49.748] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:06:28.384] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 11:06:28.384] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 11:17:52.165] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 11:17:52.750] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:17:53.087] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:17:53.088] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:17:56.032] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 11:17:56.118] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 11:17:56 CST 2017]; root of context hierarchy
[2017-12-21 11:17:56.169] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 11:17:56.263] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 11:17:56.294] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 11:17:56.376] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:17:56.377] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:17:56.402] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:17:56.405] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:17:56.406] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:17:56.408] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:17:56.409] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:17:56.410] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:17:56.410] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:17:56.411] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:17:56.412] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:17:56.413] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:17:56.413] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:17:56.414] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:17:56.415] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:17:56.415] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:17:56.434] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:17:56.434] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:17:56.437] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:17:56.667] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 11:17:56.714] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20320 (auto-detected)
[2017-12-21 11:17:56.717] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:17:56.717] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:17:56.719] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:17:56.720] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:17:56.724] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:17:56.735] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:17:56.736] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:17:56.762] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:17:56.762] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:17:56.762] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:17:56.763] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:17:56.764] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:17:56.764] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:17:56.772] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:17:56.772] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:17:56.772] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:17:56.789] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x601f9189] REGISTERED
[2017-12-21 11:17:56.790] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x601f9189] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 11:17:56.793] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 11:17:56.794] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x601f9189, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 11:17:56.981] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:17:56.986] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:17:56.986] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 11:17:57.035] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:17:57.037] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:17:57.037] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:17:57.055] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 11:17:57.055] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:17:57.055] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 11:17:58.191] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 11:17:59.071] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:17:59.073] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:17:59.073] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:18:08.511] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 11:18:08.619] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5f058f00: startup date [Thu Dec 21 11:18:08 CST 2017]; root of context hierarchy
[2017-12-21 11:18:08.686] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 11:18:08.829] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 11:18:08.906] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 11:18:09.035] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:18:09.037] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:18:09.074] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:18:09.078] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:18:09.079] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:18:09.080] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:18:09.081] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:18:09.083] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:18:09.083] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:18:09.084] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:18:09.086] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:18:09.086] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:18:09.088] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:18:09.089] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:18:09.090] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:18:09.091] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:18:09.116] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:18:09.116] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:18:09.119] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:18:09.350] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 11:18:09.386] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20325 (auto-detected)
[2017-12-21 11:18:09.389] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:18:09.389] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:18:09.394] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:18:09.395] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:18:09.397] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:18:09.408] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:18:09.408] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:18:09.434] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:18:09.434] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:18:09.435] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:18:09.436] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:18:09.436] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:18:09.445] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:18:09.445] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:18:09.445] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:18:09.466] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x1817c811] REGISTERED
[2017-12-21 11:18:09.468] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x1817c811] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 11:18:09.471] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 11:18:09.472] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x1817c811, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 11:18:09.656] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:18:09.662] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:18:09.662] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 11:18:09.725] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:18:09.725] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:18:09.725] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:18:09.745] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 11:18:09.745] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:18:09.745] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 11:18:33.375] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:18:33.378] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:18:33.402] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:18:33.406] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:18:33.407] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:18:33.408] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:18:33.409] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:18:33.410] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:18:33.411] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:18:33.412] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:18:33.413] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:18:33.414] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:18:33.415] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:18:33.415] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:18:33.416] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:18:33.417] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:18:33.434] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:18:33.434] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:18:33.436] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:18:33.479] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20329 (auto-detected)
[2017-12-21 11:18:33.481] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:18:33.482] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:18:33.483] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:18:33.484] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:18:33.486] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:18:33.498] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:18:33.499] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:18:33.523] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:18:33.523] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:18:33.523] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:18:33.524] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:18:33.524] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:18:33.524] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:18:33.524] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:18:33.524] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:18:33.525] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:18:33.525] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:18:33.525] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:18:33.533] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:18:33.533] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:18:33.533] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:18:33.611] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 11:18:33.622] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x1817c811, L:/0:0:0:0:0:0:0:0:10010] RECEIVED: [id: 0x7f69787d, L:/127.0.0.1:10010 - R:/127.0.0.1:53770]
[2017-12-21 11:18:33.639] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 11:18:33.639] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 11:18:33.640] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 11:18:33.748] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 11:18:33.753] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:18:33.753] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:18:33.753] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:18:33.754] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:18:33.757] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 11:18:33.775] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:18:33.777] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@3b7b74aa
[2017-12-21 11:18:33.780] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:18:33.997] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:18:34.006] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:18:34.012] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:18:34.012] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:18:34.020] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:18:34.020] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:18:34.021] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:18:34.021] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:18:34.031] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:18:34.033] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@5735d593
[2017-12-21 11:18:34.039] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:18:34.044] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:18:34.045] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:53770, package length = 186
[2017-12-21 11:18:34.056] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:18:34.239] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:18:34.240] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 11:18:34.315] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:18:34.356] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 11:18:34.357] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 11:18:34.357] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 11:18:34.357] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 11:18:34.357] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 11:18:34.357] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:18:34.358] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-0@20
[2017-12-21 11:18:34.358] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:18:34.358] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 11:18:34.358] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:18:34.373] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:18:34.374] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:18:34.380] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:18:34.381] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:18:34.381] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:18:34.386] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:18:34.388] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:18:34.389] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 11:18:34.394] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:18:34.395] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:21:54.703] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 11:21:54.703] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 11:21:54.716] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 11:31:53.981] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-1]
[2017-12-21 11:34:48.626] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 11:34:48.628] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 11:34:48.651] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:34:48.651] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-1]
[2017-12-21 11:34:48.665] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 11:34:49.635] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:34:49.661] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:34:49.661] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 11:34:56.433] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 11:34:56.524] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5f058f00: startup date [Thu Dec 21 11:34:56 CST 2017]; root of context hierarchy
[2017-12-21 11:34:56.585] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 11:34:56.687] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 11:34:56.715] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 11:34:56.822] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:34:56.824] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:34:56.849] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:34:56.853] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:34:56.854] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:34:56.856] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:34:56.857] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:34:56.858] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:34:56.859] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:34:56.860] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:34:56.861] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:34:56.862] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:34:56.863] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:34:56.863] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:34:56.864] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:34:56.865] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:34:56.906] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:34:56.906] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:34:56.910] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:34:57.139] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 11:34:57.183] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20438 (auto-detected)
[2017-12-21 11:34:57.186] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:34:57.186] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:34:57.191] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:34:57.192] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:34:57.194] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:34:57.210] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:34:57.211] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:34:57.237] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:34:57.237] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:34:57.237] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:34:57.237] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:34:57.237] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:34:57.238] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:34:57.238] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:34:57.238] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:34:57.238] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:34:57.238] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:34:57.239] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:34:57.248] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:34:57.248] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:34:57.249] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:34:57.270] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0xb3c4a3d1] REGISTERED
[2017-12-21 11:34:57.272] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0xb3c4a3d1] BIND: 0.0.0.0/0.0.0.0:10010
[2017-12-21 11:34:57.275] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 64] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 11:34:57.276] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0xb3c4a3d1, L:/0:0:0:0:0:0:0:0:10010] ACTIVE
[2017-12-21 11:34:57.478] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:34:57.483] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 11:34:57.484] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 11:34:57.545] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:34:57.545] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:34:57.579] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 11:34:57.583] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 11:35:00.596] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 11:35:00.619] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 11:35:00.620] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 11:35:00.620] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 11:35:18.966] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 11:35:18.968] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 11:35:18.984] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 11:35:18.987] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 11:35:18.988] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 11:35:18.989] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 11:35:18.990] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 11:35:18.991] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 11:35:18.991] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 11:35:18.992] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 11:35:18.993] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 11:35:18.993] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 11:35:18.994] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 11:35:18.994] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 11:35:18.995] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 11:35:18.995] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 11:35:19.010] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 11:35:19.011] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 11:35:19.012] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 11:35:19.053] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20442 (auto-detected)
[2017-12-21 11:35:19.055] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 11:35:19.056] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 11:35:19.058] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 11:35:19.058] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 11:35:19.061] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 11:35:19.073] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 11:35:19.073] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 11:35:19.096] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 11:35:19.097] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 11:35:19.097] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 11:35:19.097] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 11:35:19.097] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 11:35:19.098] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 11:35:19.098] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 11:35:19.098] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 11:35:19.099] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 11:35:19.099] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 11:35:19.099] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 11:35:19.107] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 11:35:19.107] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 11:35:19.108] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 11:35:19.180] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 11:35:19.187] [INFO ] [nioEventLoopGroup-2-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0xb3c4a3d1, L:/0:0:0:0:0:0:0:0:10010] RECEIVED: [id: 0x786f3495, L:/127.0.0.1:10010 - R:/127.0.0.1:53938]
[2017-12-21 11:35:19.196] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 11:35:19.197] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 11:35:19.197] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 11:35:19.327] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 11:35:19.334] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:35:19.334] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:35:19.334] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:35:19.334] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:35:19.337] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 11:35:19.352] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:35:19.354] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@6d927399
[2017-12-21 11:35:19.357] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:35:19.573] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:35:19.580] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:35:19.582] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:35:19.582] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:35:19.590] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 11:35:19.591] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 11:35:19.591] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 11:35:19.591] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 11:35:19.600] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 11:35:19.602] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@33465721
[2017-12-21 11:35:19.606] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:35:19.609] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:35:19.610] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:53938, package length = 186
[2017-12-21 11:35:19.618] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:35:19.822] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:35:19.822] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 11:35:19.900] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:35:19.945] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:35:19.946] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-1@21
[2017-12-21 11:35:19.947] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 11:35:19.947] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:35:19.947] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 11:35:19.962] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 11:35:19.963] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 11:35:19.970] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 11:35:19.970] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 11:35:19.970] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 11:35:19.975] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 11:35:19.977] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 11:35:19.978] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 11:35:19.984] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 11:35:19.985] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 11:38:23.276] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 11:38:23.276] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 11:38:23.276] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 11:45:32.475] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 259] - User provided listener org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$1 for group 0 failed on partition assignment
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:766)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:712)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:764)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:745)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:186)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:149)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:116)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:493)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:322)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:253)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:578)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1125)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$1.onPartitionsAssigned(KafkaMessageListenerContainer.java:451)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:255)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:339)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:303)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:286)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 11:45:32.475] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 259] - User provided listener org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$1 for group 0 failed on partition assignment
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:766)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:712)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:764)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:745)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:186)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:149)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:116)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:493)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:322)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:253)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:188)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:578)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1125)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$1.onPartitionsAssigned(KafkaMessageListenerContainer.java:451)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete(ConsumerCoordinator.java:255)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:339)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:303)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:286)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1030)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:995)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:556)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
[2017-12-21 11:47:31.201] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : 259] - User provided listener org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer$1 for group 0 failed on partition assignment
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:766)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:712)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:764)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:745)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:186)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:149)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:116)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:493)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:322)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:253)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:263)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:887)
[2017-12-21 11:47:48.678] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 418] - Invalid state: the invoker was not active, but the consumer had allocated partitions
[2017-12-21 11:47:48.678] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 418] - Invalid state: the invoker was not active, but the consumer had allocated partitions
[2017-12-21 11:47:54.724] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 11:47:57.589] [ERROR] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 418] - Invalid state: the invoker was not active, but the consumer had allocated partitions
[2017-12-21 11:47:57.590] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-1]
[2017-12-21 11:48:08.515] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-2, connection-test-1]
[2017-12-21 13:58:11.987] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 13:58:11.989] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 13:58:12.025] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 13:58:12.033] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 13:58:12.035] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 13:58:12.091] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 13:58:21.790] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 13:58:21.867] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 13:58:21 CST 2017]; root of context hierarchy
[2017-12-21 13:58:21.909] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 13:58:21.997] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 13:58:22.025] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 13:58:22.094] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 13:58:22.095] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 13:58:22.111] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 13:58:22.113] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 13:58:22.113] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 13:58:22.114] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 13:58:22.115] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 13:58:22.115] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 13:58:22.115] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 13:58:22.116] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 13:58:22.117] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 13:58:22.117] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 13:58:22.118] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 13:58:22.118] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 13:58:22.120] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 13:58:22.120] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 13:58:22.139] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 13:58:22.139] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 13:58:22.141] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 13:58:22.319] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 13:58:22.353] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20876 (auto-detected)
[2017-12-21 13:58:22.356] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 13:58:22.356] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 13:58:22.358] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 13:58:22.359] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 13:58:22.362] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 13:58:22.374] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 13:58:22.374] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 13:58:22.395] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 13:58:22.396] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 13:58:22.396] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 13:58:22.396] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 13:58:22.396] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 13:58:22.396] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 13:58:22.397] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 13:58:22.397] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 13:58:22.397] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 13:58:22.397] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 13:58:22.397] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 13:58:22.405] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 13:58:22.405] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 13:58:22.406] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 13:58:22.419] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 65] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 13:58:22.581] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 13:58:22.585] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 13:58:22.585] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 13:58:22.638] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 13:58:22.640] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 13:58:22.640] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 13:58:22.656] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 13:58:22.656] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 13:58:22.656] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 13:58:56.661] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 13:58:56.667] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 13:58:56.689] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 13:58:56.691] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 13:58:56.692] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 13:58:56.693] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 13:58:56.694] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 13:58:56.695] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 13:58:56.695] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 13:58:56.696] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 13:58:56.697] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 13:58:56.698] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 13:58:56.698] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 13:58:56.698] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 13:58:56.699] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 13:58:56.700] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 13:58:56.722] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 13:58:56.722] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 13:58:56.724] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 13:58:56.768] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20883 (auto-detected)
[2017-12-21 13:58:56.770] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 13:58:56.770] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 13:58:56.772] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 13:58:56.773] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 13:58:56.775] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 13:58:56.786] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 13:58:56.787] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 13:58:56.808] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 13:58:56.808] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 13:58:56.808] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 13:58:56.808] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 13:58:56.809] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 13:58:56.809] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 13:58:56.809] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 13:58:56.809] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 13:58:56.809] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 13:58:56.810] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 13:58:56.810] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 13:58:56.817] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 13:58:56.818] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 13:58:56.818] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 13:58:56.896] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 13:58:56.920] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 - R:/127.0.0.1:54644] REGISTERED
[2017-12-21 13:58:56.921] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 13:58:56.921] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 - R:/127.0.0.1:54644] ACTIVE
[2017-12-21 13:58:56.921] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 13:58:56.921] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 13:58:57.031] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 13:58:57.034] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 13:58:57.034] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 13:58:57.034] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 13:58:57.034] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 13:58:57.036] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 13:58:57.049] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 13:58:57.050] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@44d56d8e
[2017-12-21 13:58:57.053] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 13:58:57.261] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 13:58:57.273] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 13:58:57.275] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 13:58:57.275] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 13:58:57.286] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 13:58:57.287] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 13:58:57.287] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 13:58:57.288] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 13:58:57.299] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 13:58:57.300] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@4b5a75cd
[2017-12-21 13:58:57.305] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 - R:/127.0.0.1:54644] RECEIVED: 186B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 64 00 ba 70 6b 2b 66 72 5c 31 30 30 30 30 20 |hd..pk+fr\10000 |
|00000010| 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 |                |
|00000020| 20 20 20 20 20 20 20 20 20 20 45 51 f4 33 b5 2d |          EQ.3.-|
|00000030| 3c 93 9f 5e c3 cb 1b 8e 4f 4d 8f d1 2a e4 0f 9b |<..^....OM..*...|
|00000040| cd 06 de 23 60 bb e4 6f 72 25 54 50 36 98 e9 0c |...#`..or%TP6...|
|00000050| bf b9 27 9a 67 85 8f eb 12 c8 c9 8f 7b 1d ef cb |..'.g.......{...|
|00000060| f5 f3 fb 1c b9 89 80 3e 39 e2 34 db 27 43 f7 af |.......>9.4.'C..|
|00000070| 69 0c ee 32 13 c7 47 8e 7a a9 b9 28 e6 49 86 7c |i..2..G.z..(.I.||
|00000080| e8 84 c5 81 c6 11 c4 82 66 bf a6 3b f3 bc 26 e4 |........f..;..&.|
|00000090| 6e 9f b9 56 e5 ee 67 ae af 68 67 f9 63 23 7a 20 |n..V..g..hg.c#z |
|000000a0| 88 3d 7b 14 04 45 68 c1 8a e4 31 36 77 6a b7 72 |.={..Eh...16wj.r|
|000000b0| f8 51 ab f1 06 51 25 cf ff 2d                   |.Q...Q%..-      |
+--------+-------------------------------------------------+----------------+
[2017-12-21 13:58:57.305] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 13:58:57.307] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 13:58:57.308] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:54644, package length = 186
[2017-12-21 13:58:57.316] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 13:58:57.505] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 13:58:57.506] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 13:58:57.570] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 13:58:57.609] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 13:58:57.609] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 13:58:57.609] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 13:58:57.609] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 13:58:57.609] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 13:58:57.610] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 13:58:57.610] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 13:58:57.610] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 13:58:57.610] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-2@19
[2017-12-21 13:58:57.610] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 13:58:57.625] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 13:58:57.626] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 13:58:57.633] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 13:58:57.633] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 13:58:57.634] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 13:58:57.634] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 - R:/127.0.0.1:54644] WRITE: 186B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 64 00 ba 70 6b 2b 66 72 5c 31 30 30 30 30 20 |hd..pk+fr\10000 |
|00000010| 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 |                |
|00000020| 20 20 20 20 20 20 20 20 20 20 45 51 f4 33 b5 2d |          EQ.3.-|
|00000030| 3c 93 9f 5e c3 cb 1b 8e 4f 4d 8f d1 2a e4 0f 9b |<..^....OM..*...|
|00000040| cd 06 de 23 60 bb e4 6f 72 25 54 50 36 98 e9 0c |...#`..or%TP6...|
|00000050| bf b9 27 9a 67 85 8f eb 12 c8 c9 8f 7b 1d ef cb |..'.g.......{...|
|00000060| f5 f3 fb 1c b9 89 80 3e 39 e2 34 db 27 43 f7 af |.......>9.4.'C..|
|00000070| 69 0c ee 32 13 c7 47 8e 7a a9 b9 28 e6 49 86 7c |i..2..G.z..(.I.||
|00000080| e8 84 c5 81 c6 11 c4 82 66 bf a6 3b f3 bc 26 e4 |........f..;..&.|
|00000090| 6e 9f b9 56 e5 ee 67 ae af 68 67 f9 63 23 7a 20 |n..V..g..hg.c#z |
|000000a0| 88 3d 7b 14 04 45 68 c1 8a e4 31 36 77 6a b7 72 |.={..Eh...16wj.r|
|000000b0| f8 51 ab f1 06 51 25 cf ff 2d                   |.Q...Q%..-      |
+--------+-------------------------------------------------+----------------+
[2017-12-21 13:58:57.635] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 - R:/127.0.0.1:54644] FLUSH
[2017-12-21 13:58:57.639] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 13:58:57.641] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 13:58:57.642] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 13:58:57.648] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 13:58:57.649] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 14:00:13.772] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 ! R:/127.0.0.1:54644] INACTIVE
[2017-12-21 14:00:13.772] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 14:00:13.773] [INFO ] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 101] - [id: 0x89857065, L:/127.0.0.1:10010 ! R:/127.0.0.1:54644] UNREGISTERED
[2017-12-21 14:00:13.773] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 14:11:21.243] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 14:11:21.883] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:11:22.011] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:11:22.057] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:11:25.133] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 14:11:25.211] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 14:11:25 CST 2017]; root of context hierarchy
[2017-12-21 14:11:25.255] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 14:11:25.345] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 14:11:25.374] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 14:11:25.445] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 14:11:25.446] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 14:11:25.462] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 14:11:25.464] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 14:11:25.465] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 14:11:25.466] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 14:11:25.467] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 14:11:25.467] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 14:11:25.468] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 14:11:25.468] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 14:11:25.470] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 14:11:25.470] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 14:11:25.471] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 14:11:25.472] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 14:11:25.473] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 14:11:25.473] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 14:11:25.493] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 14:11:25.494] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 14:11:25.495] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 14:11:25.691] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 49] - Starting TCP Server...
[2017-12-21 14:11:25.731] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20966 (auto-detected)
[2017-12-21 14:11:25.734] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 14:11:25.734] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 14:11:25.736] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 14:11:25.737] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 14:11:25.740] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 14:11:25.756] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 14:11:25.757] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 14:11:25.789] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 14:11:25.789] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 14:11:25.790] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 14:11:25.790] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 14:11:25.791] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 14:11:25.791] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 14:11:25.791] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 14:11:25.792] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 14:11:25.792] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 14:11:25.792] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 14:11:25.792] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 14:11:25.800] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 14:11:25.801] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 14:11:25.803] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 14:11:25.813] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 65] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 14:11:25.978] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 14:11:25.981] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 14:11:25.982] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 14:11:26.035] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:11:26.035] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:11:26.035] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:11:26.054] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 14:11:26.054] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 14:11:26.054] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 14:11:32.137] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 14:11:32.141] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 14:11:32.157] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 14:11:32.159] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 14:11:32.160] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 14:11:32.161] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 14:11:32.161] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 14:11:32.162] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 14:11:32.162] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 14:11:32.163] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 14:11:32.164] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 14:11:32.164] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 14:11:32.165] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 14:11:32.165] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 14:11:32.166] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 14:11:32.166] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 14:11:32.182] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 14:11:32.183] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 14:11:32.186] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 14:11:32.231] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 20969 (auto-detected)
[2017-12-21 14:11:32.233] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 14:11:32.233] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 14:11:32.235] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 14:11:32.236] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 14:11:32.238] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 14:11:32.249] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 14:11:32.249] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 14:11:32.271] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 14:11:32.271] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 14:11:32.271] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 14:11:32.271] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 14:11:32.272] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 14:11:32.273] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 14:11:32.281] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 14:11:32.281] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 14:11:32.281] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 14:11:32.353] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 14:11:32.375] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 - R:/127.0.0.1:54748] REGISTERED
[2017-12-21 14:11:32.376] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 34] - Server channel--register
[2017-12-21 14:11:32.376] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 - R:/127.0.0.1:54748] ACTIVE
[2017-12-21 14:11:32.376] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 49] - Server channel--active
[2017-12-21 14:11:32.376] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 51] - Device IP : => /127.0.0.1
[2017-12-21 14:11:32.475] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 14:11:32.479] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 14:11:32.479] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 14:11:32.479] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 14:11:32.480] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 14:11:32.482] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 14:11:32.494] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 14:11:32.496] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@148136a8
[2017-12-21 14:11:32.498] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 14:11:32.710] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 14:11:32.720] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 14:11:32.722] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 14:11:32.722] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 14:11:32.729] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 14:11:32.729] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 14:11:32.729] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 14:11:32.730] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 14:11:32.738] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 14:11:32.739] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@37cc5ca8
[2017-12-21 14:11:32.743] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 - R:/127.0.0.1:54748] RECEIVED: 186B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 64 00 ba 70 6b 2b 66 72 5c 31 30 30 30 30 20 |hd..pk+fr\10000 |
|00000010| 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 |                |
|00000020| 20 20 20 20 20 20 20 20 20 20 45 51 f4 33 b5 2d |          EQ.3.-|
|00000030| 3c 93 9f 5e c3 cb 1b 8e 4f 4d 8f d1 2a e4 0f 9b |<..^....OM..*...|
|00000040| cd 06 de 23 60 bb e4 6f 72 25 54 50 36 98 e9 0c |...#`..or%TP6...|
|00000050| bf b9 27 9a 67 85 8f eb 12 c8 c9 8f 7b 1d ef cb |..'.g.......{...|
|00000060| f5 f3 fb 1c b9 89 80 3e 39 e2 34 db 27 43 f7 af |.......>9.4.'C..|
|00000070| 69 0c ee 32 13 c7 47 8e 7a a9 b9 28 e6 49 86 7c |i..2..G.z..(.I.||
|00000080| e8 84 c5 81 c6 11 c4 82 66 bf a6 3b f3 bc 26 e4 |........f..;..&.|
|00000090| 6e 9f b9 56 e5 ee 67 ae af 68 67 f9 63 23 7a 20 |n..V..g..hg.c#z |
|000000a0| 88 3d 7b 14 04 45 68 c1 8a e4 31 36 77 6a b7 72 |.={..Eh...16wj.r|
|000000b0| f8 51 ab f1 06 51 25 cf ff 2d                   |.Q...Q%..-      |
+--------+-------------------------------------------------+----------------+
[2017-12-21 14:11:32.744] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 14:11:32.746] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 14:11:32.747] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:54748, package length = 186
[2017-12-21 14:11:32.753] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 14:11:32.931] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 27] - Server Receive CommandPackage => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 14:11:32.931] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 28] - Send Response Object to MQ
[2017-12-21 14:11:33.001] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 26] - send message BaseCommandDTO json string => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 14:11:33.039] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 36] - isInterestedInSuccess execute!!
[2017-12-21 14:11:33.039] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 16] - ========== kafka发送数据成功（日志开始）==========
[2017-12-21 14:11:33.040] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 17] - ----------topic:connection-test
[2017-12-21 14:11:33.040] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 18] - ----------partition:null
[2017-12-21 14:11:33.040] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 19] - ----------key:null
[2017-12-21 14:11:33.040] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 20] - ----------value:{"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 14:11:33.040] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaAcknowledgeListener : 21] - receive message from MQ => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 14:11:33.041] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 21] - ----------RecordMetadata:connection-test-1@22
[2017-12-21 14:11:33.041] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-L-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaMQReceiver : 27] - receive mq message jsonContent => {"deviceIp":"/127.0.0.1","loginServer":"192.168.2.85","payload":"{\"sysVersion\":\"iOS 8.2\",\"serial\":\"100\",\"hardwareVersion\":\"hardware 1.0\",\"language\":\"chinese\",\"cmd\":0,\"source\":\"S20\",\"softwareVersion\":\"v1.0.0\"}","pt":"pk","sessionID":"10000"}
[2017-12-21 14:11:33.041] [INFO ] [kafka-producer-network-thread | producer-1] [com.orvibo.cloud.connection.server.mq.kafka.KafkaProducerListener : 22] - ========== kafka发送数据成功（日志结束）==========
[2017-12-21 14:11:33.056] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 14:11:33.057] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 14:11:33.062] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 14:11:33.063] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 14:11:33.063] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 14:11:33.063] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 - R:/127.0.0.1:54748] WRITE: 186B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 64 00 ba 70 6b 2b 66 72 5c 31 30 30 30 30 20 |hd..pk+fr\10000 |
|00000010| 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 |                |
|00000020| 20 20 20 20 20 20 20 20 20 20 45 51 f4 33 b5 2d |          EQ.3.-|
|00000030| 3c 93 9f 5e c3 cb 1b 8e 4f 4d 8f d1 2a e4 0f 9b |<..^....OM..*...|
|00000040| cd 06 de 23 60 bb e4 6f 72 25 54 50 36 98 e9 0c |...#`..or%TP6...|
|00000050| bf b9 27 9a 67 85 8f eb 12 c8 c9 8f 7b 1d ef cb |..'.g.......{...|
|00000060| f5 f3 fb 1c b9 89 80 3e 39 e2 34 db 27 43 f7 af |.......>9.4.'C..|
|00000070| 69 0c ee 32 13 c7 47 8e 7a a9 b9 28 e6 49 86 7c |i..2..G.z..(.I.||
|00000080| e8 84 c5 81 c6 11 c4 82 66 bf a6 3b f3 bc 26 e4 |........f..;..&.|
|00000090| 6e 9f b9 56 e5 ee 67 ae af 68 67 f9 63 23 7a 20 |n..V..g..hg.c#z |
|000000a0| 88 3d 7b 14 04 45 68 c1 8a e4 31 36 77 6a b7 72 |.={..Eh...16wj.r|
|000000b0| f8 51 ab f1 06 51 25 cf ff 2d                   |.Q...Q%..-      |
+--------+-------------------------------------------------+----------------+
[2017-12-21 14:11:33.064] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 - R:/127.0.0.1:54748] FLUSH
[2017-12-21 14:11:33.068] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 14:11:33.071] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 14:11:33.071] [DEBUG] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:10010, package length = 186
[2017-12-21 14:11:33.077] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 14:11:33.078] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.ClientPackageInboundHandler : 48] - response object => head= {hd}, length= {186}, protocolType= {pk}, crc= {2B66725C}, sessionID= {10000}, payload= {{"sysVersion":"iOS 8.2","serial":"100","hardwareVersion":"hardware 1.0","language":"chinese","cmd":0,"source":"S20","softwareVersion":"v1.0.0"}}
[2017-12-21 14:11:55.890] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 ! R:/127.0.0.1:54748] INACTIVE
[2017-12-21 14:11:55.890] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 44] - Server channel--inactive
[2017-12-21 14:11:55.891] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x780bc45a, L:/127.0.0.1:10010 ! R:/127.0.0.1:54748] UNREGISTERED
[2017-12-21 14:11:55.891] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageInboundHandler : 39] - Server channel--unregistered
[2017-12-21 14:18:34.983] [INFO ] [Thread-1] [org.springframework.context.support.DefaultLifecycleProcessor : 368] - Stopping beans in phase 0
[2017-12-21 14:18:35.333] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:18:35.334] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:18:35.334] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer : 621] - Consumer stopped
[2017-12-21 14:18:52.852] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 18] - cloud connection service starting...
[2017-12-21 14:18:52.930] [INFO ] [main] [org.springframework.context.support.ClassPathXmlApplicationContext : 589] - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@5ce81285: startup date [Thu Dec 21 14:18:52 CST 2017]; root of context hierarchy
[2017-12-21 14:18:52.974] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-server.xml]
[2017-12-21 14:18:53.063] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-consumer.xml]
[2017-12-21 14:18:53.089] [INFO ] [main] [org.springframework.beans.factory.xml.XmlBeanDefinitionReader : 316] - Loading XML bean definitions from class path resource [spring-kafka-producer.xml]
[2017-12-21 14:18:53.157] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 14:18:53.158] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 14:18:53.175] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 14:18:53.178] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 14:18:53.180] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 14:18:53.180] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 14:18:53.181] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 14:18:53.182] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 14:18:53.182] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 14:18:53.183] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 14:18:53.184] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 14:18:53.184] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 14:18:53.184] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 14:18:53.185] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 14:18:53.186] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 14:18:53.186] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 14:18:53.204] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 14:18:53.205] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 14:18:53.207] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 14:18:53.393] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 50] - Starting TCP Server...
[2017-12-21 14:18:53.424] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 21017 (auto-detected)
[2017-12-21 14:18:53.426] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 14:18:53.427] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 14:18:53.428] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 14:18:53.429] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 14:18:53.431] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 14:18:53.441] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 14:18:53.442] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 14:18:53.464] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 14:18:53.465] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 14:18:53.465] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 14:18:53.465] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 14:18:53.465] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 14:18:53.466] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 14:18:53.466] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 14:18:53.466] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 14:18:53.467] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 14:18:53.467] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 14:18:53.467] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 14:18:53.477] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 14:18:53.477] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 14:18:53.478] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 14:18:53.489] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.netty.second.NettyTCPServer : 68] - start TCP server 192.168.2.85 successfully on port 10010
[2017-12-21 14:18:53.652] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 14:18:53.657] [INFO ] [main] [org.springframework.context.support.DefaultLifecycleProcessor : 353] - Starting beans in phase 0
[2017-12-21 14:18:53.657] [INFO ] [main] [com.orvibo.cloud.connection.server.Main : 21] - cloud connection service started
[2017-12-21 14:18:53.712] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:18:53.712] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:18:53.712] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[]
[2017-12-21 14:18:53.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 14:18:53.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 14:18:53.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 14:19:06.958] [DEBUG] [main] [io.netty.util.internal.logging.InternalLoggerFactory : 71] - Using SLF4J as the default logging framework
[2017-12-21 14:19:06.961] [DEBUG] [main] [io.netty.channel.MultithreadEventLoopGroup : 76] - -Dio.netty.eventLoopThreads: 16
[2017-12-21 14:19:06.979] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noUnsafe: false
[2017-12-21 14:19:06.981] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.theUnsafe: available
[2017-12-21 14:19:06.982] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - sun.misc.Unsafe.copyMemory: available
[2017-12-21 14:19:06.983] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - java.nio.Buffer.address: available
[2017-12-21 14:19:06.983] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 71] - direct buffer constructor: available
[2017-12-21 14:19:06.984] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.Bits.unaligned: available, true
[2017-12-21 14:19:06.984] [DEBUG] [main] [io.netty.util.internal.PlatformDependent0 : 76] - java.nio.DirectByteBuffer.<init>(long, int): available
[2017-12-21 14:19:06.985] [DEBUG] [main] [io.netty.util.internal.Cleaner0 : 71] - java.nio.ByteBuffer.cleaner(): available
[2017-12-21 14:19:06.986] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - Java version: 8
[2017-12-21 14:19:06.986] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - sun.misc.Unsafe: available
[2017-12-21 14:19:06.987] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.tmpdir: /var/folders/gq/wpjzqchn7y13wl56phgjbtfh0000gn/T (java.io.tmpdir)
[2017-12-21 14:19:06.987] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.bitMode: 64 (sun.arch.data.model)
[2017-12-21 14:19:06.988] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - -Dio.netty.noPreferDirect: false
[2017-12-21 14:19:06.988] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 76] - io.netty.maxDirectMemory: 3817865216 bytes
[2017-12-21 14:19:07.005] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.noKeySetOptimization: false
[2017-12-21 14:19:07.005] [DEBUG] [main] [io.netty.channel.nio.NioEventLoop : 76] - -Dio.netty.selectorAutoRebuildThreshold: 512
[2017-12-21 14:19:07.007] [DEBUG] [main] [io.netty.util.internal.PlatformDependent : 71] - org.jctools-core.MpscChunkedArrayQueue: available
[2017-12-21 14:19:07.049] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.processId: 21020 (auto-detected)
[2017-12-21 14:19:07.052] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv4Stack: false
[2017-12-21 14:19:07.052] [DEBUG] [main] [io.netty.util.NetUtil : 76] - -Djava.net.preferIPv6Addresses: false
[2017-12-21 14:19:07.054] [DEBUG] [main] [io.netty.util.NetUtil : 86] - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1)
[2017-12-21 14:19:07.054] [DEBUG] [main] [io.netty.util.NetUtil : 81] - /proc/sys/net/core/somaxconn: 128 (non-existent)
[2017-12-21 14:19:07.057] [DEBUG] [main] [io.netty.channel.DefaultChannelId : 76] - -Dio.netty.machineId: 00:0e:c6:ff:fe:d3:ca:41 (auto-detected)
[2017-12-21 14:19:07.069] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.level: simple
[2017-12-21 14:19:07.070] [DEBUG] [main] [io.netty.util.ResourceLeakDetector : 81] - -Dio.netty.leakDetection.maxRecords: 4
[2017-12-21 14:19:07.094] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numHeapArenas: 16
[2017-12-21 14:19:07.094] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.numDirectArenas: 16
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.pageSize: 8192
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxOrder: 11
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.chunkSize: 16777216
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.tinyCacheSize: 512
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.smallCacheSize: 256
[2017-12-21 14:19:07.095] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.normalCacheSize: 64
[2017-12-21 14:19:07.096] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
[2017-12-21 14:19:07.096] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.cacheTrimInterval: 8192
[2017-12-21 14:19:07.096] [DEBUG] [main] [io.netty.buffer.PooledByteBufAllocator : 76] - -Dio.netty.allocator.useCacheForAllThreads: true
[2017-12-21 14:19:07.103] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.allocator.type: pooled
[2017-12-21 14:19:07.104] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.threadLocalDirectBufferSize: 65536
[2017-12-21 14:19:07.104] [DEBUG] [main] [io.netty.buffer.ByteBufUtil : 76] - -Dio.netty.maxThreadLocalCharBufferSize: 16384
[2017-12-21 14:19:07.191] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.command.CommandJsonReader : 22] - file path => /Users/sunlin/work/cloud/connection/server/target/test-classes/com/orvibo/cloud/connection/server/tcp/command/RequestKey.json
[2017-12-21 14:19:07.216] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 - R:/127.0.0.1:54830] REGISTERED
[2017-12-21 14:19:07.216] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.TestCloseHandler : 26] - Server channel--register
[2017-12-21 14:19:07.217] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 - R:/127.0.0.1:54830] ACTIVE
[2017-12-21 14:19:07.217] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.TestCloseHandler : 41] - Server channel--active
[2017-12-21 14:19:07.294] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 51] - Channel Send message.....
[2017-12-21 14:19:07.298] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 14:19:07.299] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 14:19:07.299] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 14:19:07.299] [DEBUG] [main] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 14:19:07.301] [INFO ] [main] [com.orvibo.cloud.connection.server.tcp.NettyClient : 53] - Channel Send message finished.
[2017-12-21 14:19:07.314] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 14:19:07.316] [DEBUG] [nioEventLoopGroup-2-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@6d927399
[2017-12-21 14:19:07.319] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 20] - PackageEncoder start encode command package....
[2017-12-21 14:19:07.548] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 117] - payload crc string => 2B66725C
[2017-12-21 14:19:07.560] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.CommandParser : 125] - payload.length=> 144, send payload byte is [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45], bytebuf.length=>186
[2017-12-21 14:19:07.562] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 28] - byteBuf.readableBytes() = 186
[2017-12-21 14:19:07.562] [INFO ] [nioEventLoopGroup-2-1] [com.orvibo.cloud.connection.server.tcp.netty.PackageEncoder : 29] - PackageEncoder finish encode command package....
[2017-12-21 14:19:07.569] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxCapacityPerThread: 32768
[2017-12-21 14:19:07.570] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.maxSharedCapacityFactor: 2
[2017-12-21 14:19:07.570] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.linkCapacity: 16
[2017-12-21 14:19:07.570] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.Recycler : 76] - -Dio.netty.recycler.ratio: 8
[2017-12-21 14:19:07.580] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.buffer.AbstractByteBuf : 81] - -Dio.netty.buffer.bytebuf.checkAccessible: true
[2017-12-21 14:19:07.582] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.util.ResourceLeakDetectorFactory : 76] - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@7176db8d
[2017-12-21 14:19:07.586] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 - R:/127.0.0.1:54830] RECEIVED: 186B
         +-------------------------------------------------+
         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 68 64 00 ba 70 6b 2b 66 72 5c 31 30 30 30 30 20 |hd..pk+fr\10000 |
|00000010| 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 |                |
|00000020| 20 20 20 20 20 20 20 20 20 20 45 51 f4 33 b5 2d |          EQ.3.-|
|00000030| 3c 93 9f 5e c3 cb 1b 8e 4f 4d 8f d1 2a e4 0f 9b |<..^....OM..*...|
|00000040| cd 06 de 23 60 bb e4 6f 72 25 54 50 36 98 e9 0c |...#`..or%TP6...|
|00000050| bf b9 27 9a 67 85 8f eb 12 c8 c9 8f 7b 1d ef cb |..'.g.......{...|
|00000060| f5 f3 fb 1c b9 89 80 3e 39 e2 34 db 27 43 f7 af |.......>9.4.'C..|
|00000070| 69 0c ee 32 13 c7 47 8e 7a a9 b9 28 e6 49 86 7c |i..2..G.z..(.I.||
|00000080| e8 84 c5 81 c6 11 c4 82 66 bf a6 3b f3 bc 26 e4 |........f..;..&.|
|00000090| 6e 9f b9 56 e5 ee 67 ae af 68 67 f9 63 23 7a 20 |n..V..g..hg.c#z |
|000000a0| 88 3d 7b 14 04 45 68 c1 8a e4 31 36 77 6a b7 72 |.={..Eh...16wj.r|
|000000b0| f8 51 ab f1 06 51 25 cf ff 2d                   |.Q...Q%..-      |
+--------+-------------------------------------------------+----------------+
[2017-12-21 14:19:07.587] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 28] - Package2ObjectDecoder decode ByteBuf...
[2017-12-21 14:19:07.589] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 42] - Package2ObjectDecoder parseBuffer...
[2017-12-21 14:19:07.590] [DEBUG] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.second.Package2ObjectDecoder : 53] - clientIp = /127.0.0.1:54830, package length = 186
[2017-12-21 14:19:07.608] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.utils.CRCUtil : 24] - when check CRC, the passed crc string is 2B66725C, the calculated crc string is 2B66725C, payload byte = [69, 81, -12, 51, -75, 45, 60, -109, -97, 94, -61, -53, 27, -114, 79, 77, -113, -47, 42, -28, 15, -101, -51, 6, -34, 35, 96, -69, -28, 111, 114, 37, 84, 80, 54, -104, -23, 12, -65, -71, 39, -102, 103, -123, -113, -21, 18, -56, -55, -113, 123, 29, -17, -53, -11, -13, -5, 28, -71, -119, -128, 62, 57, -30, 52, -37, 39, 67, -9, -81, 105, 12, -18, 50, 19, -57, 71, -114, 122, -87, -71, 40, -26, 73, -122, 124, -24, -124, -59, -127, -58, 17, -60, -126, 102, -65, -90, 59, -13, -68, 38, -28, 110, -97, -71, 86, -27, -18, 103, -82, -81, 104, 103, -7, 99, 35, 122, 32, -120, 61, 123, 20, 4, 69, 104, -63, -118, -28, 49, 54, 119, 106, -73, 114, -8, 81, -85, -15, 6, 81, 37, -49, -1, 45]
[2017-12-21 14:19:07.803] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.TestCloseHandler : 20] - channel read  and then close context
[2017-12-21 14:19:07.803] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 - R:/127.0.0.1:54830] CLOSE
[2017-12-21 14:19:07.804] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 ! R:/127.0.0.1:54830] INACTIVE
[2017-12-21 14:19:07.812] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.TestCloseHandler : 36] - Server channel--inactive
[2017-12-21 14:19:07.812] [DEBUG] [nioEventLoopGroup-3-1] [io.netty.handler.logging.LoggingHandler : 71] - [id: 0x4b101970, L:/127.0.0.1:10010 ! R:/127.0.0.1:54830] UNREGISTERED
[2017-12-21 14:19:07.812] [INFO ] [nioEventLoopGroup-3-1] [com.orvibo.cloud.connection.server.tcp.netty.TestCloseHandler : 31] - Server channel--unregistered
[2017-12-21 15:59:20.010] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 15:59:20.010] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 15:59:20.010] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 15:59:20.022] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 15:59:20.022] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 15:59:20.022] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 16:50:27.964] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 16:50:27.964] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 16:50:27.964] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 16:50:27.974] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 16:50:27.974] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 16:50:27.974] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 18:21:06.910] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 18:21:06.910] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 18:21:06.910] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 18:52:22.316] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 18:52:22.317] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 18:52:22.318] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 18:58:21.744] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 18:58:21.744] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 18:58:21.744] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 18:58:21.763] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 18:58:21.764] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 18:58:21.764] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 20:20:18.801] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 20:20:18.801] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 20:20:18.801] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 20:20:18.815] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 20:20:18.815] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 20:20:18.816] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 22:08:20.805] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 22:08:20.804] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 22:08:20.805] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 22:08:20.823] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 22:08:20.823] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 22:08:20.824] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 23:02:08.694] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 23:02:08.694] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 23:02:08.712] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0, connection-test-1]
[2017-12-21 23:02:08.713] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 23:02:09.702] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 23:02:11.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0, connection-test-1]
[2017-12-21 23:02:11.729] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 23:02:11.757] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 23:02:11.758] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 23:02:11.758] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
[2017-12-21 23:11:32.678] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-0]
[2017-12-21 23:11:32.678] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-1]
[2017-12-21 23:11:32.678] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 242] - partitions revoked:[connection-test-2]
[2017-12-21 23:11:32.692] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-2-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-2]
[2017-12-21 23:11:32.692] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-0-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-0]
[2017-12-21 23:11:32.692] [INFO ] [connectionTestTopicConcurrentMessageListenerContainer-1-C-1] [org.springframework.kafka.listener.ConcurrentMessageListenerContainer : 247] - partitions assigned:[connection-test-1]
